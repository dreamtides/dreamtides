{"id":"dr-00o","title":"LLMC v2: Commands - init and add","description":"## Overview\nImplement the `llmc init` and `llmc add` commands.\n\n## Context\n`init` sets up a new LLMC project directory. `add` creates a new worker. See `rules_engine/docs/llmc2.md` command reference for specifications.\n\n## Deliverables\n1. Implement `src/commands/init.rs`:\n   - `run_init(source: Option\u003cPathBuf\u003e, target: Option\u003cPathBuf\u003e)` -\u003e Result\u003c()\u003e\n   - Default target: ~/llmc\n   - Clone source repository with `--local` flag\n   - Configure git rerere\n   - Install LFS if available\n   - Create directory structure:\n     - ~/llmc/config.toml (template with commented options)\n     - ~/llmc/state.json (empty initial state)\n     - ~/llmc/logs/\n     - ~/llmc/.worktrees/\n   - Copy Tabula.xlsm if present (from source repo)\n\n2. Implement `src/commands/add.rs`:\n   - `run_add(name: \u0026str, model: Option\u003cString\u003e, role_prompt: Option\u003cString\u003e)` -\u003e Result\u003c()\u003e\n   - Validate worker name (alphanumeric, no special chars)\n   - Create git worktree at .worktrees/\u003cname\u003e\n   - Create branch llmc/\u003cname\u003e\n   - Copy Tabula.xlsm to worktree\n   - Add worker to state.json with status=offline\n   - Add worker to config.toml if model/role_prompt specified\n   - Print success message\n\n3. Update CLI in `src/cli.rs`:\n   - init command args: --source \u003cpath\u003e, --target \u003cpath\u003e\n   - add command args: \u003cname\u003e, --model \u003cmodel\u003e, --role-prompt \u003cprompt\u003e\n\n4. Config template for init:\n```toml\n[defaults]\nmodel = \"opus\"\nskip_permissions = true\n# allowed_tools = [\"Bash\", \"Edit\", \"Read\", \"Write\", \"Glob\", \"Grep\"]\n# patrol_interval_secs = 60\n# sound_on_review = true\n\n[repo]\nsource = \"\u003cSOURCE_PATH\u003e\"\n\n# [workers.example]\n# model = \"sonnet\"\n# role_prompt = \"You are Example, focused on...\"\n```\n\n5. Error handling:\n   - Target already exists -\u003e error with suggestion\n   - Source not a git repo -\u003e error\n   - Worker name already exists -\u003e error\n   - Invalid worker name -\u003e error with valid name rules\n\n## Dependencies\n- Requires: dr-oqc (scaffolding), dr-4ll (config), dr-rrk (state), dr-pyx (git)\n\n## Testing Instructions\n- Run `cargo test commands::init`\n- Run `cargo test commands::add`\n- Test init with valid source repo\n- Test add with various names\n\n## Acceptance Criteria\n- [ ] init creates all directories and files\n- [ ] init clones repo with --local\n- [ ] add creates worktree and branch\n- [ ] add updates state.json\n- [ ] Error messages are clear and actionable\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nAfter completing this task, output a \"Manual Testing Instructions\" section describing how to manually verify the work.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T06:56:05.749232-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:56:05.749232-08:00","dependencies":[{"issue_id":"dr-00o","depends_on_id":"dr-5vq","type":"blocks","created_at":"2026-01-10T06:58:39.693072-08:00","created_by":"dthurn"}]}
{"id":"dr-1nm","title":"LLMC v2: Error Recovery System","description":"## Overview\nImplement comprehensive error recovery for all failure modes.\n\n## Context\nThe system must handle various failure modes gracefully. See `rules_engine/docs/llmc2-appendix-error-recovery.md` for detailed decision trees for each failure type.\n\n## Deliverables\n1. Create `src/recovery.rs`:\n   - `RecoveryManager` struct\n   - Recovery functions for each failure mode\n   - Logging and diagnostics\n\n2. Lost Input Recovery (from appendix):\n   - `handle_lost_input(worker: \u0026mut Worker, message: \u0026str)` -\u003e Result\u003c()\u003e\n   - Attempt 1: Increase debounce +200ms, resend\n   - Attempt 2: Use load-buffer method\n   - Attempt 3: Kill pane, respawn Claude, resend\n   - After 3 failures: mark ERROR, notify user\n\n3. Session Crash Recovery:\n   - `handle_session_crash(worker: \u0026mut Worker)` -\u003e Result\u003c()\u003e\n   - Classify crash type (rate limit, user exit, fatal)\n   - Rate limit: wait 5 min, retry\n   - User exit: reset to idle\n   - Other crash: increment crash_count, auto-restart\n   - After 3 crashes: mark ERROR, require manual intervention\n   - Context restoration: respawn Claude, send /clear, resend original prompt\n\n4. Stuck Processing Recovery:\n   - `handle_stuck_worker(worker: \u0026mut Worker)` -\u003e Result\u003c()\u003e\n   - Check for commit (transition to needs_review)\n   - Check for question (transition to needs_input)\n   - Send nudge messages at thresholds\n   - Final escalation to needs_input with alert\n\n5. Partial Send Recovery:\n   - `handle_partial_send(worker: \u0026mut Worker, message: \u0026str)` -\u003e Result\u003c()\u003e\n   - Detect partial input in pane\n   - Clear with Ctrl-U\n   - Retry with increased debounce\n   - After 3 failures: mark ERROR\n\n6. State Corruption Recovery:\n   - `handle_state_corruption(path: \u0026Path)` -\u003e Result\u003cState\u003e\n   - Try restore from backup\n   - If backup fails: guided manual recovery\n   - Option to rebuild from filesystem\n\n7. Recovery logging:\n   - Log all recovery actions with context\n   - Include pane output, git status\n   - Write to worker's log file\n   - Provide diagnostic bundle on escalation\n\n8. RecoveryLogEntry struct:\n   - timestamp: DateTime\n   - worker: String\n   - action: RecoveryAction enum\n   - context: String\n   - pane_output: Option\u003cString\u003e\n   - git_status: Option\u003cString\u003e\n   - success: bool\n\n9. User notification on escalation:\n```\nWorker 'adam' requires manual intervention.\n\nError: Lost input after 3 retry attempts\n\nDiagnostics:\n  - Status: working\n  - Last activity: 5 minutes ago\n  - Prompt: \"Implement the user authentication flow...\"\n\nRecent pane output:\n  \u003e Implement the user aut\n  [cursor]\n\nSuggested actions:\n  1. llmc attach adam  - Connect to session manually\n  2. llmc message adam \"...\" - Send follow-up message\n  3. llmc nuke adam \u0026\u0026 llmc add adam  - Recreate worker\n```\n\n10. Crash count tracking:\n    - Increment on crash\n    - Reset to 0 on successful task completion\n    - Reset after 24 hours\n    - Store last_crash_unix in worker record\n\n## Dependencies\n- Requires: dr-wcq (tmux sender for resend)\n- Requires: dr-sga (tmux session for respawn)\n- Requires: dr-9m8 (state detection)\n- Requires: dr-rrk (state management)\n\n## Testing Instructions\n- Run `cargo test recovery`\n- Test each recovery path with simulated failures\n- Test crash count tracking\n- Test diagnostic bundle generation\n\n## Acceptance Criteria\n- [ ] Lost input recovered with retry logic\n- [ ] Session crashes handled appropriately\n- [ ] Stuck workers receive nudges\n- [ ] State corruption recovery works\n- [ ] Clear user notifications on escalation\n- [ ] Recovery actions logged\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nAfter completing this task, output a \"Manual Testing Instructions\" section describing how to manually verify the work.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T06:58:24.717036-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:58:24.717036-08:00","dependencies":[{"issue_id":"dr-1nm","depends_on_id":"dr-jgc","type":"blocks","created_at":"2026-01-10T06:58:40.337633-08:00","created_by":"dthurn"}]}
{"id":"dr-43h","title":"LLMC2: Document error recovery strategies","description":"LLMC2 design identifies several failure modes but recovery strategies need more detail: (1) Lost input: how many retries before escalating? (2) Session crash: should we auto-restart or wait for user? (3) Stuck processing: timeout thresholds? (4) Partial sends: detection mechanism? (5) State corruption: how to validate and repair state.json? Document decision trees for each failure mode. See docs/llmc2.md 'Failure Recovery' section.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-10T04:47:11.813748-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:40:40.565487-08:00","closed_at":"2026-01-10T06:40:40.565487-08:00","close_reason":"Closed"}
{"id":"dr-4ll","title":"LLMC v2: Configuration System","description":"## Overview\nImplement the configuration loading system for LLMC v2, reading from `~/llmc/config.toml`.\n\n## Context\nLLMC v2 uses a TOML configuration file for global settings and per-worker configuration. See `rules_engine/docs/llmc2.md` section \"Configuration\" for the full specification.\n\n## Deliverables\n1. Implement `src/config.rs`:\n   - Define `Config` struct with all fields from design doc\n   - Define `WorkerConfig` struct for per-worker settings\n   - Define `DefaultsConfig` for global defaults\n   - Implement `Config::load(path: \u0026Path)` -\u003e Result\u003cConfig\u003e\n   - Implement validation for required fields\n   - Implement default values for optional fields\n\n2. Configuration fields to support:\n   - `defaults.model` (default: \"opus\")\n   - `defaults.skip_permissions` (default: true)\n   - `defaults.allowed_tools` (default: [\"Bash\", \"Edit\", \"Read\", \"Write\", \"Glob\", \"Grep\"])\n   - `defaults.patrol_interval_secs` (default: 60)\n   - `defaults.sound_on_review` (default: true)\n   - `repo.source` (required)\n   - `workers.\u003cname\u003e.model` (inherits from defaults)\n   - `workers.\u003cname\u003e.role_prompt` (optional)\n   - `workers.\u003cname\u003e.excluded_from_pool` (default: false)\n\n3. Add helper functions:\n   - `get_llmc_root()` -\u003e PathBuf (returns ~/llmc)\n   - `get_config_path()` -\u003e PathBuf\n   - `Config::get_worker(\u0026self, name: \u0026str)` -\u003e Option\u003c\u0026WorkerConfig\u003e\n\n## Out of Scope\n- State file operations (separate task)\n- Actually using the config in commands (later tasks)\n\n## Testing Instructions\n- Create a test config.toml with sample values\n- Run unit tests: `cargo test config`\n- Verify default values are applied correctly\n\n## Acceptance Criteria\n- [ ] Config struct parses all documented fields\n- [ ] Defaults are applied for missing optional fields\n- [ ] Invalid configs return descriptive errors\n- [ ] Workers inherit from defaults when fields unspecified\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nAfter completing this task, output a \"Manual Testing Instructions\" section describing how to manually verify the work.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T06:54:34.866195-08:00","created_by":"dthurn","updated_at":"2026-01-10T08:24:45.216337-08:00","closed_at":"2026-01-10T08:24:45.216337-08:00","close_reason":"Configuration system implemented with all required structs, validation, default values, and comprehensive unit tests. All checks pass.","dependencies":[{"issue_id":"dr-4ll","depends_on_id":"dr-oqc","type":"blocks","created_at":"2026-01-10T06:58:39.059659-08:00","created_by":"dthurn"}]}
{"id":"dr-5vq","title":"LLMC v2: Worker Lifecycle Management","description":"## Overview\nImplement the worker lifecycle and state machine transitions.\n\n## Context\nEach worker progresses through a well-defined state machine. See `rules_engine/docs/llmc2.md` section \"Worker State Machine\" for the state diagram and transition rules.\n\n## Deliverables\n1. Implement `src/worker.rs`:\n\n2. Worker initialization:\n   - `Worker` struct representing a live worker\n   - `Worker::new(config: \u0026WorkerConfig, state: \u0026WorkerRecord)` -\u003e Worker\n   - `initialize_worker(name: \u0026str, config: \u0026Config, state: \u0026mut State)` -\u003e Result\u003cWorker\u003e\n\n3. State machine transitions:\n   - `WorkerTransition` enum:\n     - None (no change)\n     - ToIdle\n     - ToWorking { prompt: String }\n     - ToNeedsInput\n     - ToNeedsReview { commit_sha: String }\n     - ToRejected { feedback: String }\n     - ToRebasing\n     - ToError { reason: String }\n     - ToOffline\n   - `apply_transition(worker: \u0026mut WorkerRecord, transition: WorkerTransition)` -\u003e Result\u003c()\u003e\n\n4. Transition validation:\n   - `can_transition(from: \u0026WorkerStatus, to: \u0026WorkerStatus)` -\u003e bool\n   - Valid transitions:\n     - idle -\u003e working (start task)\n     - working -\u003e needs_review (commit created)\n     - working -\u003e needs_input (stopped without commit)\n     - needs_input -\u003e working (message sent)\n     - needs_review -\u003e idle (accepted)\n     - needs_review -\u003e rejected (rejected with feedback)\n     - rejected -\u003e needs_review (fixes committed)\n     - rejected -\u003e idle (accepted after fixes)\n     - any -\u003e rebasing (rebase triggered)\n     - rebasing -\u003e previous state (rebase complete)\n     - any -\u003e error (unrecoverable error)\n     - any -\u003e offline (session lost)\n\n5. Worker startup sequence:\n   - `start_claude_in_session(session: \u0026str, config: \u0026WorkerConfig)` -\u003e Result\u003c()\u003e\n   - Build Claude command with flags (--model, --dangerously-skip-permissions, etc.)\n   - Wait for Claude to initialize\n   - Accept bypass permissions warning\n   - Send /clear\n   - Mark as idle\n\n6. Worker teardown:\n   - `shutdown_worker(worker: \u0026Worker)` -\u003e Result\u003c()\u003e\n   - Send Ctrl-C to session\n   - Wait for graceful exit\n   - Clean up resources\n\n7. Prompt building:\n   - `build_prompt_preamble(worker: \u0026Worker)` -\u003e String\n   - Include worktree location, repo root\n   - Instructions to follow conventions\n   - Run validation commands\n   - Create single commit\n   - Don't push to remote\n\n## Out of Scope\n- Actual command implementations using workers (later tasks)\n- Error recovery logic (handled in separate task)\n\n## Testing Instructions\n- Run `cargo test worker`\n- Test transition validation logic\n- Test prompt preamble generation\n\n## Acceptance Criteria\n- [ ] State transitions validated correctly\n- [ ] Invalid transitions rejected with clear errors\n- [ ] Startup sequence brings worker to idle state\n- [ ] Prompt preamble includes all required instructions\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nAfter completing this task, output a \"Manual Testing Instructions\" section describing how to manually verify the work.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T06:56:05.565602-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:56:05.565602-08:00","dependencies":[{"issue_id":"dr-5vq","depends_on_id":"dr-pyx","type":"blocks","created_at":"2026-01-10T06:58:39.626261-08:00","created_by":"dthurn"}]}
{"id":"dr-5zp","title":"LLMC v2: Commands - up and down","description":"## Overview\nImplement the `llmc up` and `llmc down` commands - the core daemon functionality.\n\n## Context\n`up` starts the LLMC daemon, bringing up all worker sessions and running the main monitoring loop. `down` stops all workers. See `rules_engine/docs/llmc2.md` command reference.\n\n## Deliverables\n1. Implement `src/commands/up.rs`:\n   - `run_up(no_patrol: bool)` -\u003e Result\u003c()\u003e\n   - Load configuration\n   - Validate state file\n   - Start TMUX server if not running\n   - For each worker in config:\n     - Create worktree if missing\n     - Create TMUX session if missing\n     - Start Claude in session\n     - Initialize to idle state\n   - Enter main loop:\n     - Poll worker states periodically\n     - Detect state transitions\n     - Run patrol if enabled (configurable interval)\n     - Handle graceful shutdown on Ctrl-C\n\n2. Main loop implementation:\n   - Poll interval: 1 second\n   - For each worker:\n     - Get current Claude state from tmux/monitor\n     - Compare to recorded state\n     - Apply transitions if needed\n     - Update state.json\n   - Patrol runs on configured interval (default 60s)\n\n3. Shutdown handling:\n   - Register Ctrl-C handler (using ctrlc crate)\n   - On shutdown signal:\n     - Set shutdown flag\n     - For each worker: send Ctrl-C to session\n     - Wait for graceful exit (timeout 5s)\n     - Save final state\n     - Exit cleanly\n\n4. Implement `src/commands/down.rs`:\n   - `run_down(force: bool)` -\u003e Result\u003c()\u003e\n   - Send Ctrl-C to all worker sessions\n   - Wait for graceful exit\n   - If force: kill sessions after timeout\n   - Mark all workers as offline in state\n\n5. Update CLI in `src/cli.rs`:\n   - up command args: --no-patrol\n   - down command args: --force\n\n6. Session startup sequence (per worker):\n   - Create TMUX session with correct dimensions\n   - Set environment variables\n   - Send Claude startup command\n   - Wait for \"\u003e\" prompt (poll with timeout)\n   - Accept bypass permissions dialog if shown\n   - Send /clear\n   - Mark worker as idle\n\n7. Reconciliation on startup:\n   - Compare state.json workers to TMUX sessions\n   - Mark workers with missing sessions as offline\n   - Create sessions for offline workers\n   - Log discrepancies\n\n## Dependencies\n- Requires: dr-oqc, dr-4ll, dr-rrk, dr-sga, dr-9m8, dr-pyx, dr-wcq (all foundation tasks)\n- Requires: worker lifecycle (for startup sequence)\n\n## Testing Instructions\n- Run `cargo test commands::up`\n- Run `cargo test commands::down`\n- Manually test up/down cycle\n- Test Ctrl-C handling\n\n## Acceptance Criteria\n- [ ] up starts all worker sessions\n- [ ] up enters monitoring loop\n- [ ] State transitions detected and recorded\n- [ ] Ctrl-C triggers graceful shutdown\n- [ ] down stops all workers\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nAfter completing this task, output a \"Manual Testing Instructions\" section describing how to manually verify the work.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T06:56:05.961956-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:56:05.961956-08:00","dependencies":[{"issue_id":"dr-5zp","depends_on_id":"dr-00o","type":"blocks","created_at":"2026-01-10T06:58:39.755948-08:00","created_by":"dthurn"}]}
{"id":"dr-67z","title":"LLMC v2: Agent Coordination System","description":"## Overview\n\nLLMC v2 is a complete rewrite of the LLMC agent coordination system. It manages multiple Claude Code CLI sessions running in parallel git worktrees, using TMUX for persistent session management.\n\n## Design Document\n\nFull specification: `rules_engine/docs/llmc2.md`\n- Appendix - TMUX Integration: `rules_engine/docs/llmc2-appendix-tmux.md`\n- Appendix - Claude State Detection: `rules_engine/docs/llmc2-appendix-claude-state.md`\n- Appendix - Error Recovery: `rules_engine/docs/llmc2-appendix-error-recovery.md`\n\n## Key Features\n\n- TMUX-based persistent Claude Code sessions\n- Interactive control via `llmc attach`\n- Persistent daemon (`llmc up`) with Patrol system\n- Worker state machine: idle -\u003e working -\u003e needs_review -\u003e accept/reject\n- Automated rebasing and conflict resolution\n- Sound notifications and comprehensive error recovery\n\n## Child Tasks (Sequential)\n\n1. Project Scaffolding \u0026 CLI Setup\n2. Configuration System\n3. State Management System\n4. TMUX Session Management\n5. TMUX Reliable Communication\n6. TMUX Output Monitoring \u0026 State Detection\n7. Git Operations\n8. Worker Lifecycle Management\n9. Commands - init and add\n10. Commands - up and down\n11. Commands - start and message\n12. Commands - status and attach\n13. Commands - review, accept, reject\n14. Commands - nuke and rebase\n15. Patrol System\n16. Commands - doctor\n17. Error Recovery System\n18. Sound Notifications \u0026 Final Polish\n\n## Acceptance Criteria\n\n- [ ] All commands implemented per design doc\n- [ ] All state transitions working\n- [ ] Error recovery for all documented failure modes\n- [ ] Full integration test passes","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-10T06:53:42.012611-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:58:52.93277-08:00"}
{"id":"dr-7ju","title":"LLMC v2: Patrol System","description":"## Overview\nImplement the Patrol background system that maintains system health.\n\n## Context\nThe Patrol runs periodically during `llmc up` to monitor workers and facilitate rebasing. See `rules_engine/docs/llmc2.md` section \"The Patrol System\".\n\n## Deliverables\n1. Implement `src/patrol.rs`:\n   - `Patrol` struct with configuration\n   - `run_patrol(\u0026self, state: \u0026mut State, config: \u0026Config)` -\u003e Result\u003cPatrolReport\u003e\n   - `should_run(\u0026self, last_run: Instant)` -\u003e bool\n\n2. Patrol operations:\n   - **Check session health**: Verify TMUX sessions exist and match state\n   - **Detect state transitions**: Find workers finished but not processed\n   - **Rebase pending reviews**: Keep needs_review workers rebased on master\n   - **Detect stuck workers**: Find workers that appear stuck\n\n3. Session health check:\n   - For each worker in state:\n     - Verify TMUX session exists\n     - Verify Claude process is running\n     - If session missing: mark offline\n     - If Claude crashed: attempt restart\n\n4. State transition detection:\n   - For working workers:\n     - Check if Claude is now Ready\n     - Check for new commits\n     - Transition to needs_review or needs_input\n   - For rebasing workers:\n     - Check if rebase completed\n     - Check for resolution patterns in output\n     - Transition back to previous state\n\n5. Pending review rebase:\n   - For needs_review workers:\n     - Check if master has advanced\n     - If so, trigger rebase\n     - Handle conflicts (send prompt to worker)\n\n6. Stuck worker detection:\n   - Working for \u003e30 minutes without activity\n   - Send nudge message at 30 min\n   - Send warning at 40 min\n   - Mark needs_input at 45 min\n   - Track nudge_count in worker state\n\n7. PatrolReport struct:\n   - sessions_checked: u32\n   - transitions_applied: Vec\u003c(String, WorkerTransition)\u003e\n   - rebases_triggered: Vec\u003cString\u003e\n   - stuck_workers_nudged: Vec\u003cString\u003e\n   - errors: Vec\u003cString\u003e\n\n8. Sound notification:\n   - When worker enters needs_review: play terminal bell\n   - Use sound_on_review config option\n\n9. Patrol configuration:\n   - patrol_interval_secs (default 60)\n   - stuck_timeout_mins (default 30)\n   - nudge_interval_mins (default 5)\n\n10. Thread safety:\n    - Patrol should not run if another patrol is in progress\n    - Use mutex or atomic flag\n    - Log skipped patrols\n\n## Dependencies\n- Requires: dr-9m8 (state detection)\n- Requires: dr-pyx (git operations for rebase)\n- Requires: dr-5vq (worker transitions)\n\n## Testing Instructions\n- Run `cargo test patrol`\n- Test session health detection\n- Test stuck worker detection timing\n- Test rebase trigger logic\n\n## Acceptance Criteria\n- [ ] Patrol runs on configured interval\n- [ ] Session health verified for all workers\n- [ ] State transitions detected and applied\n- [ ] Pending reviews rebased when master advances\n- [ ] Stuck workers receive nudge messages\n- [ ] Sound plays on needs_review\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nAfter completing this task, output a \"Manual Testing Instructions\" section describing how to manually verify the work.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T06:57:46.17677-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:57:46.17677-08:00","dependencies":[{"issue_id":"dr-7ju","depends_on_id":"dr-qb1","type":"blocks","created_at":"2026-01-10T06:58:40.205821-08:00","created_by":"dthurn"}]}
{"id":"dr-7m9","title":"LLMC v2: Commands - status and attach","description":"## Overview\nImplement the `llmc status` and `llmc attach` commands.\n\n## Context\n`status` displays the current state of all workers. `attach` connects to a worker's TMUX session for interactive use. See `rules_engine/docs/llmc2.md` command reference.\n\n## Deliverables\n1. Implement `src/commands/status.rs`:\n   - `run_status(json: bool)` -\u003e Result\u003c()\u003e\n   - Load state file\n   - For each worker, display:\n     - Name\n     - Status (with color coding if terminal supports it)\n     - Current branch\n     - Time in current state\n     - Commit SHA (if needs_review)\n     - Brief prompt excerpt (first 50 chars)\n\n2. Status display format (text):\n```\nWORKERS\n───────\nadam     idle        llmc/adam     5m\nbaker    working     llmc/baker    12m  \"Implement the user auth...\"\ncharlie  needs_review llmc/charlie  2m   [abc1234]\n```\n\n3. Status display format (JSON):\n```json\n{\n  \"workers\": [\n    {\n      \"name\": \"adam\",\n      \"status\": \"idle\",\n      \"branch\": \"llmc/adam\",\n      \"time_in_state_secs\": 300,\n      \"commit_sha\": null,\n      \"prompt_excerpt\": null\n    }\n  ]\n}\n```\n\n4. Color coding (using terminal colors):\n   - idle: green\n   - working: yellow\n   - needs_input: cyan\n   - needs_review: blue\n   - rejected: red\n   - rebasing: magenta\n   - error: red bold\n   - offline: gray\n\n5. Implement `src/commands/attach.rs`:\n   - `run_attach(worker: \u0026str)` -\u003e Result\u003c()\u003e\n   - Verify worker exists\n   - Verify TMUX session exists\n   - Attach to session: `tmux attach-session -t llmc-\u003cworker\u003e`\n   - This replaces the current process (exec)\n\n6. Update CLI in `src/cli.rs`:\n   - status command args: --json\n   - attach command args: \u003cworker\u003e\n\n7. Additional status info:\n   - Show summary at bottom: \"3 workers: 1 idle, 1 working, 1 needs_review\"\n   - Show if patrol is running\n   - Show uptime if daemon is running\n\n## Dependencies\n- Requires: dr-rrk (state management)\n\n## Testing Instructions\n- Run `cargo test commands::status`\n- Test status output formatting\n- Test JSON output parsing\n\n## Acceptance Criteria\n- [ ] Status shows all workers with correct info\n- [ ] Color coding works in supported terminals\n- [ ] JSON output is valid and complete\n- [ ] Attach replaces process with tmux attach\n- [ ] Error if worker/session doesn't exist\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nAfter completing this task, output a \"Manual Testing Instructions\" section describing how to manually verify the work.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T06:56:53.323447-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:56:53.323447-08:00","dependencies":[{"issue_id":"dr-7m9","depends_on_id":"dr-yu9","type":"blocks","created_at":"2026-01-10T06:58:39.88346-08:00","created_by":"dthurn"}]}
{"id":"dr-8e9","title":"LLMC2: Design Claude state detection heuristics","description":"LLMC2 needs to detect Claude Code's state by parsing terminal output. Current design uses: (1) '\u003e' prompt for ready state, (2) pane command for process health. Need to refine heuristics for: (1) Detecting when Claude is asking a yes/no question, (2) Distinguishing between 'completed' and 'waiting for input', (3) Detecting crash vs normal exit, (4) Handling tool permission prompts. Consider using Claude's --output-format options. See docs/llmc2.md 'State Detection' section.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T04:47:11.455634-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:20:25.603248-08:00","closed_at":"2026-01-10T06:20:25.603248-08:00","close_reason":"Added comprehensive State Detection Heuristics section to docs/llmc2.md covering: extended ClaudeState enum with question types and exit types, process health detection, ready state detection, AskUserQuestion multi-choice detection, tool permission prompt detection, completed vs waiting-for-input classification, crash vs normal exit detection, error state detection, complete detection flow, and state transition handling"}
{"id":"dr-8f7","title":"Add variables column to dreamwell table in XLSM template","description":"The dreamwell.toml file now uses parser_v2 variable placeholder syntax, but the dreamwell table in the XLSM template doesn't have a variables column defined. This causes validation to fail with: column variables does not match any writable column in Dreamwell. Need to add the variables column to the dreamwell table structure in the XLSM template file.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T21:05:38.206359-08:00","created_by":"dthurn","updated_at":"2026-01-09T21:34:56.465075-08:00","closed_at":"2026-01-09T21:34:56.465075-08:00","close_reason":"Variables column was manually added to dreamwell table in XLSM template by user. Rebuilt XLSM from TOML using 'just tabula build-xls' to sync new test card. Tabula validation now passes.","dependencies":[{"issue_id":"dr-8f7","depends_on_id":"dr-ulj.2","type":"blocks","created_at":"2026-01-09T21:05:38.208065-08:00","created_by":"dthurn"}]}
{"id":"dr-8wt","title":"LLMC v2: Sound Notifications \u0026 Final Polish","description":"## Overview\nImplement sound notifications and final polish for the LLMC v2 system.\n\n## Context\nSound notifications alert users when workers need attention. This task also covers final integration testing and polish. See `rules_engine/docs/llmc2.md` section \"Sound Notifications\".\n\n## Deliverables\n1. Implement `src/sound.rs`:\n   - `play_bell()` -\u003e Result\u003c()\u003e\n   - Send terminal bell character (\\x07) to stdout\n   - Check sound_on_review config option\n   - Optionally support system sounds via afplay (macOS)\n\n2. Sound triggers:\n   - Worker enters needs_review state\n   - Worker enters needs_input state (optional)\n   - Error escalation requiring manual intervention\n\n3. Integration with patrol:\n   - Call play_bell() when state transitions detected\n   - Respect sound_on_review config\n\n4. Logging setup:\n   - Configure tracing with tracing-subscriber\n   - Log levels: error, warn, info, debug, trace\n   - Default level: info\n   - Environment variable override: LLMC_LOG\n   - Log to stderr (not stdout, to not interfere with output)\n\n5. Error message polish:\n   - All user-facing errors include remediation hints\n   - Example: \"Worker 'adam' not found. Available workers: baker, charlie\"\n   - Example: \"Run 'llmc up' to start workers\"\n   - Consistent error formatting across all commands\n\n6. Help text polish:\n   - Comprehensive --help for all commands\n   - Examples in help text\n   - Version information (from Cargo.toml)\n\n7. Terminal color support:\n   - Detect terminal color capability\n   - Graceful fallback to no colors\n   - Use colors for status display, errors, warnings\n\n8. Integration testing checklist:\n   - [ ] Full workflow: init -\u003e add -\u003e up -\u003e start -\u003e review -\u003e accept\n   - [ ] Reject and re-review workflow\n   - [ ] Multiple workers in parallel\n   - [ ] Rebase with conflicts\n   - [ ] Error recovery scenarios\n   - [ ] Ctrl-C handling\n   - [ ] Doctor --repair scenarios\n\n9. Edge case handling:\n   - Empty state file (no workers)\n   - Config file missing optional sections\n   - TMUX not running\n   - Git repo in unexpected state\n   - Very long prompts (\u003e10KB)\n   - Special characters in prompts\n\n10. Performance considerations:\n    - State file writes are atomic\n    - Patrol doesn't block commands\n    - Large prompts use load-buffer\n\n11. Documentation verification:\n    - All commands match design doc\n    - All config options implemented\n    - All state transitions covered\n\n## Dependencies\n- Requires: All previous tasks complete\n\n## Testing Instructions\n- Run `cargo test`\n- Run full integration test workflow manually\n- Test sound notifications\n- Verify logging output\n\n## Acceptance Criteria\n- [ ] Sound plays on needs_review\n- [ ] Logging configured and working\n- [ ] Error messages have remediation hints\n- [ ] Help text is comprehensive\n- [ ] Terminal colors work\n- [ ] All integration tests pass\n- [ ] Edge cases handled gracefully\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nAfter completing this task, output a \"Manual Testing Instructions\" section describing how to manually verify the work.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T06:58:24.905679-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:58:24.905679-08:00","dependencies":[{"issue_id":"dr-8wt","depends_on_id":"dr-1nm","type":"blocks","created_at":"2026-01-10T06:58:40.442362-08:00","created_by":"dthurn"}]}
{"id":"dr-9m8","title":"LLMC v2: TMUX Output Monitoring \u0026 State Detection","description":"## Overview\nImplement Claude state detection by parsing TMUX terminal output.\n\n## Context\nDetecting Claude's state requires analyzing terminal output patterns. See `rules_engine/docs/llmc2-appendix-claude-state.md` for comprehensive heuristics and pattern matching code.\n\n## Deliverables\n1. Implement `src/tmux/monitor.rs`:\n   - `StateDetector` struct\n   - `detect(\u0026self, session: \u0026str)` -\u003e Result\u003cClaudeState\u003e\n   - `OutputMonitor` struct for event detection\n   - `wait_for_event(\u0026self, session: \u0026str)` -\u003e Result\u003cOutputEvent\u003e\n\n2. ClaudeState enum (extended):\n   - Ready\n   - Processing\n   - AwaitingQuestion { question_type: QuestionType }\n   - AwaitingPermission { tool_name: String }\n   - Error { error_type: ErrorType, recoverable: bool }\n   - Exited { exit_type: ExitType }\n   - Unknown\n\n3. Supporting enums:\n   - QuestionType: MultipleChoice, YesNo, FreeText\n   - ExitType: UserInitiated, Crash, Timeout, Unknown\n   - ErrorType: RateLimit, Network, ToolError, ApiError\n\n4. Detection functions:\n   - `check_process_health(session)` -\u003e ProcessHealth\n   - `is_ready_for_input(output)` -\u003e bool (check for \"\u003e \" prompt)\n   - `detect_ask_user_question(output)` -\u003e Option\u003cQuestionType\u003e\n   - `detect_permission_prompt(output)` -\u003e Option\u003cString\u003e\n   - `classify_ready_state(output)` -\u003e ReadyStateType\n   - `classify_exit(session, output)` -\u003e ExitType\n   - `detect_error_state(output)` -\u003e Option\u003c(ErrorType, bool)\u003e\n\n5. Heuristics to implement:\n   - Ready prompt: \"\u003e \" at line start in last 5 lines\n   - AskUserQuestion: numbered options (1), 2)...) + question marker\n   - Permission prompt: \"Claude wants to run/use\" + box drawing chars\n   - Completion indicators: \"created commit\", \"successfully\", etc.\n   - Question indicators: ends with \"?\", \"please let me know\", etc.\n   - Error patterns: \"rate limit\", \"429\", \"network error\", etc.\n\n6. OutputEvent enum:\n   - Committed(String) - new commit SHA\n   - CompletedNoCommit\n   - AskingQuestion\n   - NeedsConfirmation\n   - Crashed\n\n7. Bypass permissions dialog:\n   - `accept_bypass_warning(session)` -\u003e Result\u003c()\u003e\n   - Detect \"Bypass Permissions mode\" text\n   - Send Down + Enter sequence\n\n## Out of Scope\n- Acting on detected states (handled in worker/patrol tasks)\n- Commit detection from git (handled in git.rs)\n\n## Testing Instructions\n- Run `cargo test tmux::monitor`\n- Test with sample output strings for each state\n- Verify detection hierarchy works correctly\n\n## Acceptance Criteria\n- [ ] Correctly detects Ready vs Processing states\n- [ ] Identifies AskUserQuestion prompts\n- [ ] Detects permission prompts\n- [ ] Distinguishes completed vs waiting-for-input\n- [ ] Handles crash detection\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nAfter completing this task, output a \"Manual Testing Instructions\" section describing how to manually verify the work.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T06:55:18.687754-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:55:18.687754-08:00","dependencies":[{"issue_id":"dr-9m8","depends_on_id":"dr-wcq","type":"blocks","created_at":"2026-01-10T06:58:39.318193-08:00","created_by":"dthurn"}]}
{"id":"dr-a86","title":"LLMC2: Design merge conflict resolution UX","description":"When rebasing worker branches onto master, merge conflicts may occur. Need to design the UX for: (1) How to present conflicts to workers, (2) What prompt to send for conflict resolution, (3) How to detect conflict resolution completion, (4) How to handle resolution failures. Should the worker see git status output? Should we provide a structured conflict description? See docs/llmc2.md 'llmc rebase' section.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T04:47:11.635242-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:24:00.79867-08:00","closed_at":"2026-01-10T06:24:00.79867-08:00","close_reason":"Added merge conflict resolution UX design to docs/llmc2.md covering: conflict detection/presentation, resolution prompt template, completion detection state machine, and failure handling strategies"}
{"id":"dr-azr","title":"Implement test card for 'Prevent a played event which could dissolve an ally'","description":"Replace the deleted 'Test Prevent Dissolve This Turn' card (which used the removed {anchored} keyword) with a new test card for the effect: 'Prevent a played event which could dissolve an ally.' This is the replacement effect for the old anchored mechanic.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-09T21:16:42.64908-08:00","created_by":"dthurn","updated_at":"2026-01-09T21:32:55.017166-08:00","closed_at":"2026-01-09T21:32:55.017166-08:00","close_reason":"Added new test card 'Test Prevent Event Which Could Dissolve Ally' to test-cards.toml with rules text '{Prevent} a played event which could {dissolve} an ally.' Replaces deleted anchored test card. Card validates and parses successfully (39/39 test-cards pass).","dependencies":[{"issue_id":"dr-azr","depends_on_id":"dr-ulj.2","type":"blocks","created_at":"2026-01-09T21:16:42.650643-08:00","created_by":"dthurn"}]}
{"id":"dr-e36","title":"Add parser_v2 support for numbered variable placeholders (e1, e2, cards1, cards2)","description":"Test cards use numbered placeholders like {e1}, {e2}, {cards1}, {cards2} for dual activated abilities and modal abilities with different values. Parser_v2 needs to support these numbered variable names. User indicated this is a simple fix to add.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T21:20:15.866252-08:00","created_by":"dthurn","updated_at":"2026-01-09T21:32:13.33637-08:00","closed_at":"2026-01-09T21:32:13.33637-08:00","close_reason":"Added support for numbered variable placeholders (e1, e2, cards1, cards2) by implementing directive_matches_with_suffix helper and split_numbered_directive function. All test-cards.toml tests now pass (38/38). Changes in parser_helpers.rs and parser_substitutions.rs.","dependencies":[{"issue_id":"dr-e36","depends_on_id":"dr-ulj.2","type":"blocks","created_at":"2026-01-09T21:20:15.8677-08:00","created_by":"dthurn"}]}
{"id":"dr-jgc","title":"LLMC v2: Commands - doctor","description":"## Overview\nImplement the `llmc doctor` command for health checks and auto-repair.\n\n## Context\nDoctor runs comprehensive health checks on the LLMC system. See `rules_engine/docs/llmc2.md` command reference and `llmc2-appendix-error-recovery.md` section \"State Corruption Recovery\".\n\n## Deliverables\n1. Implement `src/commands/doctor.rs`:\n   - `run_doctor(repair: bool, rebuild: bool)` -\u003e Result\u003cDoctorReport\u003e\n   - Run all health checks\n   - Report issues found\n   - If --repair: attempt auto-repair\n   - If --rebuild: reconstruct state from filesystem\n\n2. Health checks to implement:\n   - **Binary checks**: tmux, git, claude (in PATH)\n   - **Config checks**: config.toml exists and valid\n   - **State checks**: state.json exists and valid\n   - **Session checks**: TMUX sessions match workers\n   - **Worktree checks**: Worktrees exist and are clean\n   - **Git checks**: git configuration correct, no orphaned branches\n   - **Consistency checks**: needs_review has commit_sha, etc.\n\n3. DoctorReport struct:\n   - checks_passed: Vec\u003cString\u003e\n   - warnings: Vec\u003cDoctorWarning\u003e\n   - errors: Vec\u003cDoctorError\u003e\n   - repairs_attempted: Vec\u003cRepairAttempt\u003e\n   - repairs_succeeded: Vec\u003cString\u003e\n   - repairs_failed: Vec\u003cString\u003e\n\n4. Auto-repair strategies (from appendix):\n   - needs_review without commit_sha: find HEAD commit or reset to needs_input\n   - working without prompt: reset to needs_input\n   - Future timestamps: set to current time\n   - Missing sessions: mark offline\n   - Orphaned worktrees: offer to remove\n\n5. Rebuild from filesystem:\n   - Scan .worktrees/ for directories\n   - Scan TMUX sessions for llmc-* pattern\n   - Reconstruct worker records:\n     - worktree exists + session exists -\u003e idle\n     - worktree exists + session missing -\u003e offline\n     - session exists + worktree missing -\u003e error\n   - Prompt user to confirm before saving\n\n6. Output format:\n```\nLLMC Doctor\n───────────\n\n✓ tmux binary found\n✓ git binary found\n✓ claude binary found\n✓ config.toml valid\n✓ state.json valid\n✓ 3 workers configured\n\n⚠ Worker 'baker' session missing (marked offline)\n⚠ Orphaned worktree: .worktrees/old-worker\n\n✗ Worker 'charlie' needs_review but no commit_sha\n\nRepairs needed: 1\nRun 'llmc doctor --repair' to attempt fixes.\n```\n\n7. Update CLI in `src/cli.rs`:\n   - doctor command args: --repair, --rebuild\n\n8. Interactive rebuild:\n```\nRebuilding state from filesystem...\n\nFound worktrees: adam, baker, charlie\nFound TMUX sessions: llmc-adam, llmc-charlie\n\nReconstructed state:\n  adam: worktree ✓, session ✓ -\u003e idle\n  baker: worktree ✓, session ✗ -\u003e offline\n  charlie: worktree ✓, session ✓ -\u003e idle\n\nSave reconstructed state? [y/N]:\n```\n\n## Dependencies\n- Requires: dr-rrk (state validation)\n- Requires: dr-4ll (config validation)\n- Requires: dr-sga (session checks)\n\n## Testing Instructions\n- Run `cargo test commands::doctor`\n- Test with various broken states\n- Test auto-repair for each scenario\n- Test rebuild process\n\n## Acceptance Criteria\n- [ ] All health checks implemented\n- [ ] Clear output for each check result\n- [ ] Auto-repair works for documented scenarios\n- [ ] Rebuild reconstructs state correctly\n- [ ] No data loss without user confirmation\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nAfter completing this task, output a \"Manual Testing Instructions\" section describing how to manually verify the work.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T06:57:46.364907-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:57:46.364907-08:00","dependencies":[{"issue_id":"dr-jgc","depends_on_id":"dr-7ju","type":"blocks","created_at":"2026-01-10T06:58:40.272617-08:00","created_by":"dthurn"}]}
{"id":"dr-jld","title":"Test Epic","status":"tombstone","priority":1,"issue_type":"epic","created_at":"2026-01-09T18:15:43.295309-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:17:53.434664-08:00","close_reason":"Closed","deleted_at":"2026-01-09T18:17:53.434664-08:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"epic"}
{"id":"dr-kq6","title":"LLMC2: Research tmux_interface crate vs raw subprocess","description":"LLMC2 design mentions tmux_interface crate for Rust TMUX bindings. Need to evaluate: (1) Does it provide all operations needed (send-keys, capture-pane, has-session, etc)? (2) Error handling quality? (3) Is it maintained? (4) Would raw subprocess calls via std::process::Command be simpler and more reliable? Gastown uses subprocess approach in Go. Consider writing a thin wrapper either way.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-10T04:47:11.992734-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:38:17.678209-08:00","closed_at":"2026-01-10T06:38:17.678209-08:00","close_reason":"Closed"}
{"id":"dr-l3x","title":"LLMC2: Research TMUX debounce timing parameters","description":"The LLMC2 design proposes debounce timing of 500ms base + 100ms/KB (capped at 2000ms) based on gastown patterns. Need to empirically test these values with Claude Code sessions to validate they work reliably. Should test: (1) Short messages vs long prompts, (2) System under load, (3) Different terminal emulators, (4) Recovery from partial sends. See docs/llmc2.md 'Reliable Communication Protocol' section.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T04:47:11.270262-08:00","created_by":"dthurn","updated_at":"2026-01-10T05:42:07.05021-08:00","closed_at":"2026-01-10T05:42:07.05021-08:00","close_reason":"Research completed. Key findings documented in docs/llmc2.md: (1) Terminal width \u003e500 cols is critical, (2) Small messages need 0ms debounce, (3) System load has minimal impact, (4) Ctrl-U recovery works, (5) Large prompts need load-buffer approach"}
{"id":"dr-mk8","title":"LLMC v2: Commands - review, accept, reject","description":"## Overview\nImplement the `llmc review`, `llmc accept`, and `llmc reject` commands - the core review workflow.\n\n## Context\nThese commands implement the human review workflow for accepting or rejecting worker changes. See `rules_engine/docs/llmc2.md` command reference sections for review, accept, and reject.\n\n## Deliverables\n1. Implement `src/commands/review.rs`:\n   - `run_review(worker: Option\u003cString\u003e, interface: ReviewInterface)` -\u003e Result\u003c()\u003e\n   - Worker selection: specified worker or oldest needs_review\n   - Error if no workers need review\n   - Trigger rebase via patrol if master has advanced\n   - Store \"last reviewed worker\" for reject/accept defaults\n   - ReviewInterface enum: Difftastic (default), VSCode\n   - Display diff:\n     - Difftastic: run `difft` on worktree changes\n     - VSCode: `code --diff` command\n   - Show commit message\n   - Show prompt that was given\n\n2. Review output format:\n```\nReviewing: baker (llmc/baker)\nCommit: abc1234\nPrompt: \"Implement user authentication...\"\n\n[diff output here]\n\nCommands:\n  llmc accept        Accept these changes\n  llmc reject \"...\"  Request changes\n```\n\n3. Implement `src/commands/accept.rs`:\n   - `run_accept(worker: Option\u003cString\u003e)` -\u003e Result\u003c()\u003e\n   - Worker selection: specified or last reviewed\n   - Verify needs_review state\n   - Ensure clean worktree\n   - Rebase onto master (handle conflicts)\n   - Squash to single commit\n   - Strip agent attribution from commit message\n   - Fast-forward merge to master\n   - Remove worktree and branch\n   - Reset worker to idle with new worktree\n   - Trigger background rebase for other needs_review workers\n   - Return new commit SHA\n\n4. Accept sequence detail:\n   - `git fetch origin`\n   - `git rebase origin/master`\n   - If conflicts: error with instructions\n   - `git reset --soft \u003cbase\u003e` (squash)\n   - `git commit --amend` (with cleaned message)\n   - In master: `git merge --ff-only \u003cbranch\u003e`\n   - Cleanup: remove worktree, delete branch\n   - Recreate: new worktree, new branch\n\n5. Implement `src/commands/reject.rs`:\n   - `run_reject(message: \u0026str)` -\u003e Result\u003c()\u003e\n   - Uses last reviewed worker\n   - Verify needs_review state\n   - Do NOT send /clear (preserve context)\n   - Build rejection message with original diff context\n   - Send message to worker\n   - Update state to rejected\n   - Update last_activity_unix\n\n6. Rejection message format:\n```\nYour changes have been reviewed and require modifications:\n\n\u003cuser's feedback\u003e\n\nPlease address these issues and commit the fixes.\nThe original diff is still available in your worktree.\n```\n\n7. Update CLI in `src/cli.rs`:\n   - review command args: [worker], --interface \u003cdifftastic|vscode\u003e\n   - accept command args: [worker]\n   - reject command args: \u003cmessage\u003e\n\n8. \"Last reviewed\" tracking:\n   - Store in state.json or separate file\n   - Updated by review command\n   - Used by accept/reject when no worker specified\n\n## Dependencies\n- Requires: dr-pyx (git operations)\n- Requires: dr-wcq (tmux sender)\n- Requires: dr-5vq (worker lifecycle)\n\n## Testing Instructions\n- Run `cargo test commands::review`\n- Run `cargo test commands::accept`\n- Run `cargo test commands::reject`\n- Test full review-\u003eaccept cycle\n- Test review-\u003ereject-\u003efix-\u003eaccept cycle\n\n## Acceptance Criteria\n- [ ] review shows diff and commit info\n- [ ] accept squashes and merges to master\n- [ ] Agent attribution stripped from commits\n- [ ] reject preserves context and sends feedback\n- [ ] Worker states transition correctly\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nAfter completing this task, output a \"Manual Testing Instructions\" section describing how to manually verify the work.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T06:56:53.505878-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:56:53.505878-08:00","dependencies":[{"issue_id":"dr-mk8","depends_on_id":"dr-7m9","type":"blocks","created_at":"2026-01-10T06:58:39.947435-08:00","created_by":"dthurn"}]}
{"id":"dr-oph","title":"Test Issue","status":"tombstone","priority":0,"issue_type":"task","created_at":"2026-01-09T17:50:41.195829-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:26:52.929392-08:00","deleted_at":"2026-01-09T18:26:52.929392-08:00","deleted_by":"daemon","delete_reason":"delete","original_type":"task"}
{"id":"dr-oqc","title":"LLMC v2: Project Scaffolding \u0026 CLI Setup","description":"## Overview\nCreate the initial Rust project structure for LLMC v2, set up dependencies, and implement the basic CLI framework.\n\n## Context\nLLMC v2 is an agent coordination system that manages multiple Claude Code CLI sessions in parallel git worktrees using TMUX. See `rules_engine/docs/llmc2.md` for the full design document.\n\nThis task creates the foundational project structure that all other tasks build upon.\n\n## Deliverables\n1. Create new Rust crate at `rules_engine/src/llmc/`\n2. Set up `Cargo.toml` with dependencies:\n   - clap (CLI framework)\n   - tokio (async runtime)\n   - serde, serde_json, toml (serialization)\n   - anyhow, thiserror (error handling)\n   - tracing, tracing-subscriber (logging)\n   - regex (output parsing)\n3. Create module structure per design doc:\n   - src/main.rs (entrypoint)\n   - src/cli.rs (clap command definitions)\n   - src/config.rs (placeholder)\n   - src/state.rs (placeholder)\n   - src/tmux/mod.rs (placeholder)\n   - src/git.rs (placeholder)\n   - src/worker.rs (placeholder)\n   - src/patrol.rs (placeholder)\n   - src/commands/mod.rs (placeholder)\n   - src/sound.rs (placeholder)\n4. Implement CLI skeleton with clap for all commands:\n   - init, up, down, add, nuke, status, start, message, attach, review, reject, accept, rebase, doctor\n5. Each command should print \"Not implemented: \u003ccommand\u003e\" for now\n\n## Out of Scope\n- Actual command implementations (handled in later tasks)\n- Configuration loading (next task)\n- State management (later task)\n\n## Testing Instructions\n- Run `cargo build -p llmc` from rules_engine/ directory to verify compilation\n- Run `cargo run -p llmc -- --help` to verify CLI help text\n- Run `cargo run -p llmc -- status` to see \"Not implemented\" message\n\n## Acceptance Criteria\n- [x] Project compiles without errors\n- [x] All commands are defined and routable\n- [x] Module structure matches design doc\n- [x] Dependencies are correctly specified\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nFrom the `rules_engine/` directory:\n\n```bash\n# View help and verify all commands are listed\ncargo run -p llmc -- --help\n\n# Test individual commands (should print \"Not implemented: \u003ccommand\u003e\")\ncargo run -p llmc -- status\ncargo run -p llmc -- init\ncargo run -p llmc -- add my-worker\ncargo run -p llmc -- start worker1 \"Fix bug\"\ncargo run -p llmc -- message worker1 \"Hello\"\n```\n\nAll commands compile and execute successfully, printing the expected \"Not implemented\" messages.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T06:53:59.371539-08:00","created_by":"dthurn","updated_at":"2026-01-10T07:48:54.297891-08:00","closed_at":"2026-01-10T07:11:56.111708-08:00","close_reason":"Closed"}
{"id":"dr-pyx","title":"LLMC v2: Git Operations","description":"## Overview\nImplement git operations for worktree management, branching, and commit handling.\n\n## Context\nLLMC v2 uses git worktrees to isolate worker environments. Each worker operates on its own branch. See `rules_engine/docs/llmc2.md` sections on Repository Layout and Merge Conflict Resolution.\n\n## Deliverables\n1. Implement `src/git.rs`:\n\n2. Worktree operations:\n   - `create_worktree(repo: \u0026Path, branch: \u0026str, worktree_path: \u0026Path)` -\u003e Result\u003c()\u003e\n   - `remove_worktree(worktree_path: \u0026Path)` -\u003e Result\u003c()\u003e\n   - `list_worktrees(repo: \u0026Path)` -\u003e Result\u003cVec\u003cWorktreeInfo\u003e\u003e\n   - `worktree_exists(worktree_path: \u0026Path)` -\u003e bool\n\n3. Branch operations:\n   - `create_branch(repo: \u0026Path, name: \u0026str, start_point: \u0026str)` -\u003e Result\u003c()\u003e\n   - `delete_branch(repo: \u0026Path, name: \u0026str, force: bool)` -\u003e Result\u003c()\u003e\n   - `branch_exists(repo: \u0026Path, name: \u0026str)` -\u003e bool\n   - `get_current_branch(worktree: \u0026Path)` -\u003e Result\u003cString\u003e\n\n4. Commit operations:\n   - `get_head_commit(worktree: \u0026Path)` -\u003e Result\u003cString\u003e\n   - `has_uncommitted_changes(worktree: \u0026Path)` -\u003e Result\u003cbool\u003e\n   - `get_commit_message(worktree: \u0026Path, sha: \u0026str)` -\u003e Result\u003cString\u003e\n   - `strip_agent_attribution(message: \u0026str)` -\u003e String\n\n5. Rebase operations:\n   - `rebase_onto(worktree: \u0026Path, target: \u0026str)` -\u003e Result\u003cRebaseResult\u003e\n   - `is_rebase_in_progress(worktree: \u0026Path)` -\u003e bool\n   - `get_conflicted_files(worktree: \u0026Path)` -\u003e Result\u003cVec\u003cString\u003e\u003e\n   - `abort_rebase(worktree: \u0026Path)` -\u003e Result\u003c()\u003e\n   - `continue_rebase(worktree: \u0026Path)` -\u003e Result\u003c()\u003e\n\n6. Merge operations (for accept):\n   - `squash_commits(worktree: \u0026Path, base: \u0026str)` -\u003e Result\u003c()\u003e\n   - `fast_forward_merge(repo: \u0026Path, branch: \u0026str)` -\u003e Result\u003c()\u003e\n\n7. Fetch/pull:\n   - `fetch_origin(repo: \u0026Path)` -\u003e Result\u003c()\u003e\n   - `pull_rebase(worktree: \u0026Path)` -\u003e Result\u003c()\u003e\n\n8. Supporting types:\n   - WorktreeInfo { path: PathBuf, branch: String, is_detached: bool }\n   - RebaseResult { success: bool, conflicts: Vec\u003cString\u003e }\n\n9. Agent attribution patterns to strip:\n   - \"Generated with [Claude Code]\"\n   - \"Co-Authored-By: Claude\"\n   - Similar patterns\n\n## Out of Scope\n- Conflict resolution prompts (handled in commands/rebase.rs)\n- Full merge conflict UI (user reviews via llmc review)\n\n## Testing Instructions\n- Run `cargo test git`\n- Test worktree creation/removal\n- Test rebase conflict detection\n\n## Acceptance Criteria\n- [ ] Worktrees created with correct branch\n- [ ] Agent attribution stripped from commit messages\n- [ ] Rebase conflicts detected correctly\n- [ ] Fast-forward merge works for clean rebases\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nAfter completing this task, output a \"Manual Testing Instructions\" section describing how to manually verify the work.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T06:55:18.865995-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:55:18.865995-08:00","dependencies":[{"issue_id":"dr-pyx","depends_on_id":"dr-9m8","type":"blocks","created_at":"2026-01-10T06:58:39.429103-08:00","created_by":"dthurn"}]}
{"id":"dr-qb1","title":"LLMC v2: Commands - nuke and rebase","description":"## Overview\nImplement the `llmc nuke` and `llmc rebase` commands.\n\n## Context\n`nuke` permanently removes a worker. `rebase` manually triggers a rebase for a worker. See `rules_engine/docs/llmc2.md` command reference.\n\n## Deliverables\n1. Implement `src/commands/nuke.rs`:\n   - `run_nuke(worker: Option\u003cString\u003e, all: bool)` -\u003e Result\u003c()\u003e\n   - If --all: nuke all workers (with confirmation)\n   - For each worker to nuke:\n     - Kill TMUX session\n     - Remove worktree\n     - Delete branch\n     - Remove from state.json\n     - Remove from config.toml (optional, just worker section)\n   - Confirmation prompt for destructive action\n\n2. Nuke confirmation:\n```\nThis will permanently remove worker 'baker':\n  - TMUX session: llmc-baker\n  - Worktree: ~/.llmc/.worktrees/baker\n  - Branch: llmc/baker\n  - Any uncommitted work will be LOST\n\nProceed? [y/N]\n```\n\n3. Implement `src/commands/rebase.rs`:\n   - `run_rebase(worker: \u0026str)` -\u003e Result\u003c()\u003e\n   - Verify worker exists\n   - Fetch latest master\n   - Attempt rebase onto master\n   - If conflicts:\n     - Mark worker as rebasing\n     - Build conflict resolution prompt\n     - Send prompt to worker\n   - If success:\n     - Keep worker in current state\n     - Log rebase completion\n\n4. Conflict resolution prompt format (from design doc):\n```\nA rebase onto master has encountered conflicts.\n\nConflicting files:\n- src/auth.rs (5 conflict markers)\n- src/lib.rs (2 conflict markers)\n\nResolution steps:\n1. Examine conflict markers (\u003c\u003c\u003c\u003c\u003c\u003c, =======, \u003e\u003e\u003e\u003e\u003e\u003e\u003e)\n2. Decide how to resolve each conflict\n3. Remove conflict markers\n4. Stage resolved files: git add \u003cfile\u003e\n5. Continue rebase: git rebase --continue\n6. Run validation: just review\n\nNotes:\n- View original versions: git show :2:\u003cfile\u003e (ours) :3:\u003cfile\u003e (theirs)\n- To abort: git rebase --abort\n```\n\n5. Update CLI in `src/cli.rs`:\n   - nuke command args: [worker], --all\n   - rebase command args: \u003cworker\u003e\n\n6. Cleanup order for nuke:\n   - Kill TMUX session first (graceful, then force)\n   - Remove worktree (git worktree remove)\n   - Delete branch (git branch -D)\n   - Update state.json\n   - Best-effort: don't fail if some steps already done\n\n7. Error handling:\n   - Worker not found -\u003e list available workers\n   - Session already killed -\u003e continue\n   - Worktree already removed -\u003e continue\n   - Rebase already in progress -\u003e show current status\n\n## Dependencies\n- Requires: dr-sga (tmux session)\n- Requires: dr-pyx (git operations)\n- Requires: dr-wcq (tmux sender for conflict prompt)\n\n## Testing Instructions\n- Run `cargo test commands::nuke`\n- Run `cargo test commands::rebase`\n- Test nuke cleans up all resources\n- Test rebase conflict handling\n\n## Acceptance Criteria\n- [ ] nuke removes all worker resources\n- [ ] nuke --all with confirmation\n- [ ] rebase detects and reports conflicts\n- [ ] Conflict prompt sent to worker\n- [ ] Worker state updated correctly\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nAfter completing this task, output a \"Manual Testing Instructions\" section describing how to manually verify the work.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T06:57:45.939205-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:57:45.939205-08:00","dependencies":[{"issue_id":"dr-qb1","depends_on_id":"dr-mk8","type":"blocks","created_at":"2026-01-10T06:58:40.140726-08:00","created_by":"dthurn"}]}
{"id":"dr-rrk","title":"LLMC v2: State Management System","description":"## Overview\nImplement the state file management system for LLMC v2, handling `~/llmc/state.json`.\n\n## Context\nLLMC v2 tracks all workers and their status in a JSON state file. See `rules_engine/docs/llmc2.md` section \"Data Model\" and `llmc2-appendix-error-recovery.md` section \"State Corruption Recovery\" for full specifications.\n\n## Deliverables\n1. Implement `src/state.rs`:\n   - Define `State` struct (collection of workers)\n   - Define `WorkerRecord` struct with all fields from design doc\n   - Define `WorkerStatus` enum (idle, working, needs_input, needs_review, rejected, rebasing, error, offline)\n\n2. WorkerRecord fields:\n   - name: String\n   - worktree_path: String\n   - branch: String\n   - status: WorkerStatus\n   - current_prompt: String\n   - created_at_unix: u64\n   - last_activity_unix: u64\n   - commit_sha: Option\u003cString\u003e\n   - session_id: String\n   - crash_count: u32 (for error recovery)\n   - last_crash_unix: Option\u003cu64\u003e\n\n3. State operations:\n   - `State::load(path: \u0026Path)` -\u003e Result\u003cState\u003e\n   - `State::save(\u0026self, path: \u0026Path)` -\u003e Result\u003c()\u003e (atomic writes)\n   - `State::get_worker(\u0026self, name: \u0026str)` -\u003e Option\u003c\u0026WorkerRecord\u003e\n   - `State::get_worker_mut(\u0026mut self, name: \u0026str)` -\u003e Option\u003c\u0026mut WorkerRecord\u003e\n   - `State::add_worker(\u0026mut self, record: WorkerRecord)`\n   - `State::remove_worker(\u0026mut self, name: \u0026str)`\n   - `State::get_idle_workers(\u0026self)` -\u003e Vec\u003c\u0026WorkerRecord\u003e\n   - `State::get_workers_needing_review(\u0026self)` -\u003e Vec\u003c\u0026WorkerRecord\u003e\n\n4. Atomic write implementation:\n   - Write to temp file first\n   - Backup current state to state.json.bak\n   - Rename temp file to state.json\n\n5. Validation:\n   - `validate_state(state: \u0026State)` -\u003e Result\u003c()\u003e\n   - Check for duplicate names\n   - Verify needs_review has commit_sha\n   - Validate timestamps aren't in future\n\n## Out of Scope\n- Auto-repair logic (handled in doctor command task)\n- Using state in commands (later tasks)\n\n## Testing Instructions\n- Run unit tests: `cargo test state`\n- Test atomic write doesn't corrupt on simulated failure\n- Test validation catches invalid states\n\n## Acceptance Criteria\n- [ ] State serializes/deserializes correctly\n- [ ] Atomic writes prevent corruption\n- [ ] Backup file is created on each save\n- [ ] Validation catches inconsistent states\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nAfter completing this task, output a \"Manual Testing Instructions\" section describing how to manually verify the work.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T06:54:35.051652-08:00","created_by":"dthurn","updated_at":"2026-01-10T08:38:14.621801-08:00","closed_at":"2026-01-10T08:38:14.621801-08:00","close_reason":"Closed","dependencies":[{"issue_id":"dr-rrk","depends_on_id":"dr-4ll","type":"blocks","created_at":"2026-01-10T06:58:39.123227-08:00","created_by":"dthurn"}]}
{"id":"dr-sga","title":"LLMC v2: TMUX Session Management","description":"## Overview\nImplement TMUX session lifecycle management for LLMC v2.\n\n## Context\nLLMC v2 uses TMUX for persistent Claude Code sessions. See `rules_engine/docs/llmc2.md` section \"TMUX Integration\" and `llmc2-appendix-tmux.md` for detailed specifications.\n\n## Deliverables\n1. Implement `src/tmux/mod.rs`:\n   - Re-export submodule types\n   - Define common TMUX constants\n\n2. Implement `src/tmux/session.rs`:\n   - `create_session(name: \u0026str, cwd: \u0026Path, width: u32, height: u32)` -\u003e Result\u003c()\u003e\n   - `kill_session(name: \u0026str)` -\u003e Result\u003c()\u003e\n   - `session_exists(name: \u0026str)` -\u003e bool\n   - `list_sessions()` -\u003e Result\u003cVec\u003cString\u003e\u003e\n   - `get_pane_command(session: \u0026str)` -\u003e Result\u003cString\u003e\n   - `capture_pane(session: \u0026str, lines: u32)` -\u003e Result\u003cString\u003e\n   - `set_env(session: \u0026str, key: \u0026str, value: \u0026str)` -\u003e Result\u003c()\u003e\n\n3. Session naming convention: `llmc-\u003cworker_name\u003e`\n\n4. Session creation requirements:\n   - Create detached session (`-d`)\n   - Set wide terminal width (`-x 500`)\n   - Set working directory to worktree\n   - Set environment variables (LLMC_WORKER, LLMC_ROOT)\n\n5. Helper functions:\n   - `session_name_for_worker(worker: \u0026str)` -\u003e String\n   - `worker_from_session_name(session: \u0026str)` -\u003e Option\u003cString\u003e\n   - `is_shell(cmd: \u0026str)` -\u003e bool (detect bash/zsh/sh/fish/dash)\n   - `is_claude_process(cmd: \u0026str)` -\u003e bool (detect node/claude/semver)\n\n## Out of Scope\n- Sending input (next task)\n- Output monitoring/state detection (separate task)\n- Starting Claude within sessions (handled by up command)\n\n## Testing Instructions\n- Run `cargo test tmux::session`\n- Manually test session creation: verify with `tmux ls`\n- Test session cleanup on kill\n\n## Acceptance Criteria\n- [ ] Sessions created with correct width/height\n- [ ] Environment variables set correctly\n- [ ] Pane capture returns recent terminal content\n- [ ] Process detection distinguishes Claude from shells\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nAfter completing this task, output a \"Manual Testing Instructions\" section describing how to manually verify the work.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T06:54:35.229864-08:00","created_by":"dthurn","updated_at":"2026-01-10T10:53:14.878292-08:00","closed_at":"2026-01-10T10:53:14.878292-08:00","close_reason":"Closed","dependencies":[{"issue_id":"dr-sga","depends_on_id":"dr-rrk","type":"blocks","created_at":"2026-01-10T06:58:39.188083-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj","title":"Tabula V2: Complete Card Data Loading Rewrite","description":"## Overview\n\nComplete rewrite of the card data loading system to replace `tabula_data` with `tabula_data_v2`. This refactor eliminates the legacy `tabula.json` file in favor of loading data directly from TOML and FTL files at runtime, parsing card abilities using `parser_v2` during game initialization, and generating code from the new CLI system.\n\n## Primary Goals\n\n1. Remove `old_tabula_cli` and all v1 tabula crates\n2. Remove all use of `rules_engine/tabula.json`\n3. Remove `is_test_card` distinction from tabula data structures\n4. Rework tabula_data to use TOML and FTL tabula system\n5. Rework tabula_ids \u0026 code generation to use new tabula system\n\n## Architecture\n\n```\nTOML/FTL FILES (cards.toml, test-cards.toml, dreamwell.toml, strings.ftl)\n                    ↓\nTABULA_DATA_V2 CRATE\n  - CardDefinitionRaw (unified, all optional fields)\n  - FluentStrings loader\n  - CardEffectRow, CardListRow\n  - PARSER_V2 Integration (runtime ability parsing)\n                    ↓\nFinal Card Definitions (CardDefinition, DreamwellCardDefinition)\n                    ↓\nTABULA_GENERATED (renamed from tabula_ids)\n  - Generated enums: CardEffectRowType, CardEffectRowTrigger, etc.\n  - Generated constants: TestCard IDs, StringId enum\n```\n\n## Key Design Decisions\n\n1. **Unified CardDefinitionRaw**: Single struct with all optional fields (no separate types per card category)\n2. **Runtime Ability Parsing**: Card abilities parsed at game start using cached `parser_v2` instance\n3. **Fluent Strings**: Two FTL sources - `strings.ftl` (UI) and `card_rules.ftl` (card text)\n4. **No DisplayedAbility**: UI renders text on-demand using `parser_v2` serializers\n5. **TabulaSource Config**: Production loads `cards.toml`, tests load `test-cards.toml`\n6. **Single-Pass Migration**: All dependent crates updated simultaneously, no feature flags\n\n## Key Files\n\n- Design doc: `rules_engine/docs/tabula/tabula_v2_design_document.md`\n- TOML source files: `rules_engine/tabula/` (symlink to client/Assets/StreamingAssets/Tabula/)\n- Existing V1 crate: `rules_engine/src/tabula_data/`\n- Target V2 crate: `rules_engine/src/tabula_data_v2/` (to be created)\n- Code gen target: `rules_engine/src/tabula_generated/` (renamed from tabula_ids)\n\n## Out of Scope\n\n- Changes to parser_v2 internals\n- New card types beyond what exists today\n- Performance optimization of ability parsing\n- UI changes beyond supporting the new serializer API\n","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-09T18:16:04.426229-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:04.426229-08:00"}
{"id":"dr-ulj.1","title":"Convert strings.toml to Fluent format (strings.ftl)","description":"dispatched_by: mayor\n\n## Objective\n\nConvert the UI strings from TOML format to Fluent (FTL) format for use with the fluent localization library.\n\n## Background\n\nThe Tabula V2 system uses Fluent for string localization. The existing `strings.toml` file needs to be converted to `strings.ftl` format. Fluent uses message IDs in kebab-case with key-value pairs.\n\n## Input File\n\n`rules_engine/tabula/strings.toml` - Current UI strings in TOML format\n\n## Output File\n\n`rules_engine/tabula/strings.ftl` - New Fluent format file\n\n## Conversion Rules\n\n1. Convert TOML keys to kebab-case FTL message IDs\n2. String values become FTL message values\n3. Preserve any comments (convert `#` TOML comments to `#` FTL comments)\n4. Handle special characters (escape `{` and `}` in FTL if they're literal)\n\nExample conversion:\n```toml\n# TOML input\ngame_title = \"Dream Tides\"\nplayer_health = \"Health: {health}\"\n```\n\n```ftl\n# FTL output\ngame-title = Dream Tides\nplayer-health = Health: { $health }\n```\n\nNote: FTL uses `{ $variable }` syntax for variables (with dollar sign).\n\n## Files to Read First\n\n1. `rules_engine/tabula/strings.toml` - Source file to convert\n2. Any existing `.ftl` files in the codebase for format reference\n\n## Deliverables\n\n1. Create `rules_engine/tabula/strings.ftl` with all converted strings\n2. Preserve all existing string keys (just converted to kebab-case)\n3. Ensure variables are properly converted to FTL syntax\n\n## Out of Scope\n\n- Deleting `strings.toml` (done in cleanup milestone)\n- Updating any code to use the new file\n- Adding new strings\n\n## Acceptance Criteria\n\n- [ ] `strings.ftl` file exists at `rules_engine/tabula/strings.ftl`\n- [ ] All strings from `strings.toml` are present in `strings.ftl`\n- [ ] Message IDs are in kebab-case format\n- [ ] Variables use FTL `{ $variable }` syntax\n- [ ] File is valid FTL syntax (can be parsed by fluent)\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:04.487303-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:30:52.635489-08:00","dependencies":[{"issue_id":"dr-ulj.1","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:04.487988-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.10","title":"Implement CardEffectRow and CardListRow types","description":"## Objective\n\nImplement `CardEffectRow` and `CardListRow` structs for loading card effects and card lists from their respective TOML files.\n\n## Background\n\nCard effects (card-fx.toml) define visual/audio effects for cards. Card lists (card-lists.toml) define named collections of cards. These use string enums initially; the generated enum types will be added in milestone 10.\n\n## Files to Modify\n\n1. `rules_engine/src/tabula_data_v2/src/card_effect_row.rs`\n2. `rules_engine/src/tabula_data_v2/src/card_list_row.rs`\n3. `rules_engine/src/tabula_data_v2/src/toml_loader.rs` - Add loading functions\n4. `rules_engine/src/tabula_data_v2/src/lib.rs` - Export types\n\n## Implementation\n\n### CardEffectRow Struct\n\n```rust\nuse serde::Deserialize;\nuse uuid::Uuid;\n\n#[derive(Debug, Clone, Deserialize)]\n#[serde(rename_all = \"kebab-case\")]\npub struct CardEffectRow {\n    pub card_id: Uuid,\n    pub effect_type: String,      // Will be enum after milestone 10\n    pub trigger: Option\u003cString\u003e,  // Will be enum after milestone 10\n    pub object_predicate: Option\u003cString\u003e,  // Will be enum after milestone 10\n    pub effect_address: Option\u003cString\u003e,\n    pub projectile_address: Option\u003cString\u003e,\n    pub sound: Option\u003cString\u003e,\n}\n\n#[derive(Debug, Deserialize)]\npub struct CardEffectsFile {\n    #[serde(rename = \"card-fx\")]\n    pub card_fx: Vec\u003cCardEffectRow\u003e,\n}\n```\n\n### CardListRow Struct\n\n```rust\n#[derive(Debug, Clone, Deserialize)]\n#[serde(rename_all = \"kebab-case\")]\npub struct CardListRow {\n    pub list_name: String,\n    pub card_id: Uuid,\n}\n\n#[derive(Debug, Deserialize)]\npub struct CardListsFile {\n    #[serde(rename = \"card-list\")]\n    pub card_list: Vec\u003cCardListRow\u003e,\n}\n```\n\n### Loading Functions\n\nAdd to `toml_loader.rs`:\n\n```rust\npub fn load_card_effects\u003cP: AsRef\u003cPath\u003e\u003e(path: P) -\u003e Result\u003cVec\u003cCardEffectRow\u003e, TabulaError\u003e {\n    let content = std::fs::read_to_string(\u0026path)?;\n    let file: CardEffectsFile = toml::from_str(\u0026content)?;\n    Ok(file.card_fx)\n}\n\npub fn load_card_lists\u003cP: AsRef\u003cPath\u003e\u003e(path: P) -\u003e Result\u003cVec\u003cCardListRow\u003e, TabulaError\u003e {\n    let content = std::fs::read_to_string(\u0026path)?;\n    let file: CardListsFile = toml::from_str(\u0026content)?;\n    Ok(file.card_list)\n}\n```\n\n## Files to Read First\n\n1. `rules_engine/tabula/card-fx.toml` - Card effects format\n2. `rules_engine/tabula/card-lists.toml` - Card lists format\n3. `rules_engine/src/tabula_data/src/card_effect_row.rs` - V1 reference\n4. `rules_engine/src/tabula_data/src/card_list_row.rs` - V1 reference\n\n## Deliverables\n\n1. Define CardEffectRow with string enum fields (for now)\n2. Define CardListRow struct\n3. Define wrapper structs for TOML deserialization\n4. Implement loading functions\n5. Write unit tests with inline TOML\n6. Export from lib.rs\n\n## Out of Scope\n\n- Converting string enums to generated enums (milestone 10)\n- Using the loaded data in game logic\n- Validating effect addresses exist\n\n## Acceptance Criteria\n\n- [ ] CardEffectRow deserializes from card-fx.toml format\n- [ ] CardListRow deserializes from card-lists.toml format\n- [ ] Loading functions work with actual TOML structure\n- [ ] Unit tests pass with inline TOML\n- [ ] String enum fields (effect_type, trigger, object_predicate) remain strings\n- [ ] `cargo test -p tabula_data_v2` passes\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:05.040384-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:05.040384-08:00","dependencies":[{"issue_id":"dr-ulj.10","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:05.041037-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.10","depends_on_id":"dr-ulj.9","type":"blocks","created_at":"2026-01-09T18:16:34.596056-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.11","title":"Rename tabula_ids crate to tabula_generated","description":"## Objective\n\nRename the `tabula_ids` crate to `tabula_generated` to better reflect its purpose as the destination for generated code.\n\n## Background\n\nThe tabula_ids crate will hold all generated code (enums, constants) from the new code generation system. The new name better describes its purpose.\n\n## Files to Modify\n\n1. `rules_engine/src/tabula_ids/Cargo.toml` - Change package name\n2. `rules_engine/Cargo.toml` - Update workspace member path\n3. All crates that depend on `tabula_ids` - Update imports\n\n## Implementation\n\n### Step 1: Rename Cargo.toml\n\nIn `src/tabula_ids/Cargo.toml`:\n```toml\n[package]\nname = \"tabula_generated\"  # Was: tabula_ids\nversion = \"0.1.0\"\nedition = \"2021\"\n```\n\n### Step 2: Rename Directory\n\nRename `src/tabula_ids/` to `src/tabula_generated/`\n\n### Step 3: Update Workspace\n\nIn `rules_engine/Cargo.toml`, update the workspace members list.\n\n### Step 4: Update Dependent Crates\n\nFind all crates with `tabula_ids` in their Cargo.toml:\n```bash\ngrep -r \"tabula_ids\" src/*/Cargo.toml\n```\n\nUpdate each to use `tabula_generated`:\n```toml\n# Before\ntabula_ids = { path = \"../tabula_ids\" }\n\n# After  \ntabula_generated = { path = \"../tabula_generated\" }\n```\n\n### Step 5: Update Imports\n\nFind all Rust imports:\n```bash\ngrep -r \"use tabula_ids\" src/\ngrep -r \"tabula_ids::\" src/\n```\n\nUpdate each:\n```rust\n// Before\nuse tabula_ids::CardId;\n\n// After\nuse tabula_generated::CardId;\n```\n\n## Files to Read First\n\n1. `rules_engine/src/tabula_ids/Cargo.toml` - Current crate config\n2. `rules_engine/Cargo.toml` - Workspace configuration\n3. `rules_engine/src/tabula_ids/src/lib.rs` - Current exports\n\n## Deliverables\n\n1. Rename directory from `tabula_ids` to `tabula_generated`\n2. Update package name in Cargo.toml\n3. Update workspace members\n4. Update all dependent Cargo.toml files\n5. Update all import statements\n\n## Out of Scope\n\n- Adding new generated code (next tasks)\n- Changing the crate's internal structure\n- Adding the generate command to tabula_cli\n\n## Acceptance Criteria\n\n- [ ] Directory is `src/tabula_generated/`\n- [ ] Package name is `tabula_generated`\n- [ ] All dependent crates compile\n- [ ] No references to `tabula_ids` remain\n- [ ] `just check` passes for entire workspace\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:05.104191-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:05.104191-08:00","dependencies":[{"issue_id":"dr-ulj.11","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:05.104943-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.11","depends_on_id":"dr-ulj.10","type":"blocks","created_at":"2026-01-09T18:16:34.659669-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.12","title":"Add generate command to tabula_cli","description":"## Objective\n\nAdd a `tabula generate` command to `tabula_cli` that generates Rust code from TOML source files.\n\n## Background\n\nThe code generation system will read TOML files (effect-types.toml, trigger-types.toml, predicate-types.toml) and generate corresponding Rust enum definitions in the tabula_generated crate.\n\n## Files to Modify\n\n1. `rules_engine/src/tabula_cli/src/main.rs` - Add generate subcommand\n2. `rules_engine/src/tabula_cli/src/commands/generate.rs` - New file\n3. `rules_engine/src/tabula_cli/src/commands/mod.rs` - Export new module\n\n## Implementation\n\n### CLI Command\n\n```rust\n// In main.rs\n#[derive(Subcommand)]\nenum Commands {\n    // ... existing commands\n    \n    /// Generate Rust code from TOML source files\n    Generate {\n        /// Output directory for generated files (default: src/tabula_generated/src/)\n        #[arg(short, long)]\n        output: Option\u003cPathBuf\u003e,\n    },\n}\n```\n\n### Generate Module Structure\n\n```rust\n// src/tabula_cli/src/commands/generate.rs\n\nuse std::path::{Path, PathBuf};\nuse anyhow::Result;\n\n/// Main entry point for code generation\npub fn run_generate(output_dir: Option\u003cPathBuf\u003e) -\u003e Result\u003c()\u003e {\n    let output = output_dir.unwrap_or_else(default_output_dir);\n    \n    println!(\"Generating code to {:?}\", output);\n    \n    // Will be implemented in next tasks:\n    // generate_effect_types(\u0026output)?;\n    // generate_trigger_types(\u0026output)?;\n    // generate_predicate_types(\u0026output)?;\n    // generate_string_ids(\u0026output)?;\n    // generate_test_cards(\u0026output)?;\n    \n    println!(\"Code generation complete!\");\n    Ok(())\n}\n\nfn default_output_dir() -\u003e PathBuf {\n    // Relative to rules_engine root\n    PathBuf::from(\"src/tabula_generated/src/\")\n}\n\nfn tabula_dir() -\u003e PathBuf {\n    // Path to TOML source files\n    PathBuf::from(\"tabula/\")\n}\n```\n\n### Code Generation Helpers\n\n```rust\n/// Generate a Rust enum from a list of variant names\npub fn generate_enum_code(\n    enum_name: \u0026str,\n    variants: \u0026[String],\n    derives: \u0026[\u0026str],\n) -\u003e String {\n    let mut code = String::new();\n    \n    // Header\n    code.push_str(\"// This file is auto-generated. Do not edit manually.\\n\\n\");\n    \n    // Derives\n    let derives_str = derives.join(\", \");\n    code.push_str(\u0026format!(\"#[derive({})]\\n\", derives_str));\n    \n    // Enum definition\n    code.push_str(\u0026format!(\"pub enum {} {{\\n\", enum_name));\n    for variant in variants {\n        code.push_str(\u0026format!(\"    {},\\n\", variant));\n    }\n    code.push_str(\"}\\n\");\n    \n    code\n}\n\n/// Write generated code to file with formatting\npub fn write_generated_file(path: \u0026Path, content: \u0026str) -\u003e Result\u003c()\u003e {\n    std::fs::write(path, content)?;\n    // Optionally run rustfmt on the file\n    Ok(())\n}\n```\n\n## Files to Read First\n\n1. `rules_engine/src/tabula_cli/src/main.rs` - Existing CLI structure\n2. `rules_engine/src/old_tabula_cli/src/tabula_codegen.rs` - V1 code generation reference\n3. `rules_engine/tabula/effect-types.toml` - Example source file\n4. `rules_engine/docs/tabula/tabula_v2_design_document.md` - Code generation section\n\n## Deliverables\n\n1. Add `generate` subcommand to tabula_cli\n2. Create `commands/generate.rs` module\n3. Implement helper functions for code generation\n4. Command runs without error (actual generation in next task)\n5. Add to commands/mod.rs exports\n\n## Out of Scope\n\n- Actually generating the enum files (next task)\n- String ID generation (milestone 11)\n- Test card constant generation (milestone 12)\n\n## Acceptance Criteria\n\n- [ ] `tabula generate` command exists and runs\n- [ ] Default output directory is src/tabula_generated/src/\n- [ ] Helper functions for enum generation work\n- [ ] `cargo build -p tabula_cli` succeeds\n- [ ] Running `tabula generate` prints completion message\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:05.168016-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:05.168016-08:00","dependencies":[{"issue_id":"dr-ulj.12","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:05.168758-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.12","depends_on_id":"dr-ulj.11","type":"blocks","created_at":"2026-01-09T18:16:35.714297-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.13","title":"Generate effect, trigger, and predicate type enums","description":"## Objective\n\nImplement code generation for `CardEffectRowType`, `CardEffectRowTrigger`, and `CardEffectRowObjectPredicate` enums from their respective TOML source files.\n\n## Background\n\nThese enums define the valid values for card effect configuration. They are generated from simple TOML files that list the valid variant names.\n\n## Files to Modify\n\n1. `rules_engine/src/tabula_cli/src/commands/generate.rs` - Add generation logic\n2. Create `rules_engine/src/tabula_generated/src/effect_types.rs` (generated)\n3. Create `rules_engine/src/tabula_generated/src/trigger_types.rs` (generated)\n4. Create `rules_engine/src/tabula_generated/src/predicate_types.rs` (generated)\n5. `rules_engine/src/tabula_generated/src/lib.rs` - Export new modules\n\n## Source Files\n\n- `rules_engine/tabula/effect-types.toml` - Effect type variants\n- `rules_engine/tabula/trigger-types.toml` - Trigger type variants\n- `rules_engine/tabula/predicate-types.toml` - Predicate type variants\n\nExample source format:\n```toml\n# effect-types.toml\neffect_types = [\n    \"FireProjectile\",\n    \"DissolveTargets\",\n    \"ApplyBuff\",\n]\n```\n\n## Implementation\n\n### TOML Parsing Structs\n\n```rust\n#[derive(Debug, Deserialize)]\npub struct EffectTypesFile {\n    pub effect_types: Vec\u003cString\u003e,\n}\n\n#[derive(Debug, Deserialize)]\npub struct TriggerTypesFile {\n    pub trigger_types: Vec\u003cString\u003e,\n}\n\n#[derive(Debug, Deserialize)]\npub struct PredicateTypesFile {\n    pub predicate_types: Vec\u003cString\u003e,\n}\n```\n\n### Generation Functions\n\n```rust\npub fn generate_effect_types(output_dir: \u0026Path) -\u003e Result\u003c()\u003e {\n    let toml_path = tabula_dir().join(\"effect-types.toml\");\n    let content = std::fs::read_to_string(\u0026toml_path)?;\n    let data: EffectTypesFile = toml::from_str(\u0026content)?;\n    \n    let code = generate_enum_with_from_str(\n        \"CardEffectRowType\",\n        \u0026data.effect_types,\n        \u0026[\"Debug\", \"Clone\", \"Copy\", \"PartialEq\", \"Eq\", \"Serialize\", \"Deserialize\"],\n    );\n    \n    write_generated_file(\u0026output_dir.join(\"effect_types.rs\"), \u0026code)?;\n    Ok(())\n}\n```\n\n### Generated Enum Format\n\n```rust\n// effect_types.rs (generated)\n// This file is auto-generated. Do not edit manually.\n\nuse serde::{Serialize, Deserialize};\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]\npub enum CardEffectRowType {\n    FireProjectile,\n    DissolveTargets,\n    ApplyBuff,\n    // ...\n}\n\nimpl CardEffectRowType {\n    pub fn from_str(s: \u0026str) -\u003e Option\u003cSelf\u003e {\n        match s {\n            \"FireProjectile\" =\u003e Some(Self::FireProjectile),\n            \"DissolveTargets\" =\u003e Some(Self::DissolveTargets),\n            \"ApplyBuff\" =\u003e Some(Self::ApplyBuff),\n            // ...\n            _ =\u003e None,\n        }\n    }\n    \n    pub fn as_str(\u0026self) -\u003e \u0026'static str {\n        match self {\n            Self::FireProjectile =\u003e \"FireProjectile\",\n            Self::DissolveTargets =\u003e \"DissolveTargets\",\n            Self::ApplyBuff =\u003e \"ApplyBuff\",\n            // ...\n        }\n    }\n}\n```\n\n## Files to Read First\n\n1. `rules_engine/tabula/effect-types.toml` - Effect types source\n2. `rules_engine/tabula/trigger-types.toml` - Trigger types source\n3. `rules_engine/tabula/predicate-types.toml` - Predicate types source\n4. `rules_engine/src/old_tabula_cli/src/tabula_codegen.rs` - V1 reference\n\n## Deliverables\n\n1. Implement generate_effect_types() function\n2. Implement generate_trigger_types() function\n3. Implement generate_predicate_types() function\n4. Generated files include from_str() and as_str() methods\n5. Update lib.rs in tabula_generated to export modules\n6. Running `tabula generate` creates all three files\n\n## Out of Scope\n\n- Updating CardEffectRow to use these enums (done after generation works)\n- String ID generation (next task)\n- Test card constants\n\n## Acceptance Criteria\n\n- [ ] `tabula generate` creates effect_types.rs\n- [ ] `tabula generate` creates trigger_types.rs\n- [ ] `tabula generate` creates predicate_types.rs\n- [ ] Generated enums have from_str() and as_str() methods\n- [ ] Generated code compiles: `cargo check -p tabula_generated`\n- [ ] `just check` passes for entire workspace\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:05.267742-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:05.267742-08:00","dependencies":[{"issue_id":"dr-ulj.13","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:05.268473-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.13","depends_on_id":"dr-ulj.12","type":"blocks","created_at":"2026-01-09T18:16:35.780047-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.14","title":"Generate StringId enum from strings.ftl","description":"## Objective\n\nGenerate the `StringId` enum from `strings.ftl` message IDs, converting kebab-case FTL IDs to PascalCase Rust enum variants.\n\n## Background\n\nThe StringId enum provides type-safe access to localized strings. Each FTL message ID becomes an enum variant, allowing compile-time verification that string keys exist.\n\n## Files to Modify\n\n1. `rules_engine/src/tabula_cli/src/commands/generate.rs` - Add FTL parsing and generation\n2. Create `rules_engine/src/tabula_generated/src/string_id.rs` (generated)\n3. `rules_engine/src/tabula_generated/src/lib.rs` - Export string_id module\n\n## Source File\n\n`rules_engine/tabula/strings.ftl` - Fluent format strings (created in milestone 1)\n\nExample FTL format:\n```ftl\ngame-title = Dream Tides\nplayer-health = Health: { $health }\ncard-draw-button = Draw Card\n```\n\n## Implementation\n\n### FTL Parsing\n\nParse FTL file to extract message IDs (lines that look like `message-id = ...`):\n\n```rust\nfn parse_ftl_message_ids(content: \u0026str) -\u003e Vec\u003cString\u003e {\n    content\n        .lines()\n        .filter_map(|line| {\n            let line = line.trim();\n            if line.is_empty() || line.starts_with('#') {\n                return None;\n            }\n            // Extract message ID before '='\n            line.split('=').next().map(|s| s.trim().to_string())\n        })\n        .filter(|id| !id.is_empty() \u0026\u0026 !id.starts_with('-'))  // Skip attributes\n        .collect()\n}\n```\n\n### Case Conversion\n\nConvert kebab-case to PascalCase:\n```rust\nfn kebab_to_pascal(s: \u0026str) -\u003e String {\n    s.split('-')\n        .map(|part| {\n            let mut chars = part.chars();\n            match chars.next() {\n                None =\u003e String::new(),\n                Some(first) =\u003e first.to_uppercase().chain(chars).collect(),\n            }\n        })\n        .collect()\n}\n```\n\nExamples:\n- `game-title` → `GameTitle`\n- `player-health` → `PlayerHealth`\n- `card-draw-button` → `CardDrawButton`\n\n### Generated Enum Format\n\n```rust\n// string_id.rs (generated)\n// This file is auto-generated. Do not edit manually.\n\nuse serde::{Serialize, Deserialize};\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]\npub enum StringId {\n    GameTitle,\n    PlayerHealth,\n    CardDrawButton,\n    // ...\n}\n\nimpl StringId {\n    /// Get the FTL message key for this string ID\n    pub fn key(\u0026self) -\u003e \u0026'static str {\n        match self {\n            Self::GameTitle =\u003e \"game-title\",\n            Self::PlayerHealth =\u003e \"player-health\",\n            Self::CardDrawButton =\u003e \"card-draw-button\",\n            // ...\n        }\n    }\n    \n    /// Parse a string ID from its FTL key\n    pub fn from_key(key: \u0026str) -\u003e Option\u003cSelf\u003e {\n        match key {\n            \"game-title\" =\u003e Some(Self::GameTitle),\n            \"player-health\" =\u003e Some(Self::PlayerHealth),\n            \"card-draw-button\" =\u003e Some(Self::CardDrawButton),\n            // ...\n            _ =\u003e None,\n        }\n    }\n}\n```\n\n### Generation Function\n\n```rust\npub fn generate_string_ids(output_dir: \u0026Path) -\u003e Result\u003c()\u003e {\n    let ftl_path = tabula_dir().join(\"strings.ftl\");\n    let content = std::fs::read_to_string(\u0026ftl_path)?;\n    let message_ids = parse_ftl_message_ids(\u0026content);\n    \n    let variants: Vec\u003c(String, String)\u003e = message_ids\n        .iter()\n        .map(|id| (kebab_to_pascal(id), id.clone()))\n        .collect();\n    \n    let code = generate_string_id_enum(\u0026variants);\n    write_generated_file(\u0026output_dir.join(\"string_id.rs\"), \u0026code)?;\n    Ok(())\n}\n```\n\n## Files to Read First\n\n1. `rules_engine/tabula/strings.ftl` - Source FTL file (created in milestone 1)\n2. `rules_engine/tabula/strings.toml` - Reference for expected message IDs\n3. `rules_engine/src/old_tabula_cli/src/tabula_codegen.rs` - V1 string generation reference\n\n## Deliverables\n\n1. Implement FTL message ID parser\n2. Implement kebab-to-pascal case converter\n3. Implement generate_string_ids() function\n4. Generated StringId enum has key() and from_key() methods\n5. Update tabula_generated/lib.rs to export string_id\n\n## Out of Scope\n\n- Using StringId in other code (migration milestone)\n- Locale fallback support\n- Validation that all keys are used\n\n## Acceptance Criteria\n\n- [ ] `tabula generate` creates string_id.rs\n- [ ] All FTL message IDs become enum variants\n- [ ] Kebab-case correctly converts to PascalCase\n- [ ] Generated enum has key() method returning original FTL key\n- [ ] Generated code compiles\n- [ ] `just check` passes\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:05.328379-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:05.328379-08:00","dependencies":[{"issue_id":"dr-ulj.14","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:05.329168-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.14","depends_on_id":"dr-ulj.13","type":"blocks","created_at":"2026-01-09T18:16:35.843406-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.15","title":"Implement TabulaSource and generate test card constants","description":"## Objective\n\nImplement the `TabulaSource` enum for differentiating production vs test card loading, and generate test card ID constants from `test-cards.toml`.\n\n## Background\n\nInstead of an `is_test_card` flag on each card, the system will use separate loading paths controlled by `TabulaSource`. Test code uses `TabulaSource::Test` which loads from `test-cards.toml`, while production uses `TabulaSource::Production` which loads from `cards.toml`.\n\n## Files to Modify\n\n1. `rules_engine/src/tabula_data_v2/src/tabula_struct.rs` - Add TabulaSource enum\n2. `rules_engine/src/tabula_cli/src/commands/generate.rs` - Add test card generation\n3. Create `rules_engine/src/tabula_generated/src/test_card.rs` (generated)\n4. `rules_engine/src/tabula_generated/src/lib.rs` - Export test_card module\n\n## Implementation\n\n### TabulaSource Enum\n\nIn `tabula_struct.rs`:\n\n```rust\n/// Determines which card files to load\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum TabulaSource {\n    /// Load production cards from cards.toml and dreamwell.toml\n    Production,\n    /// Load test cards from test-cards.toml and test-dreamwell.toml\n    Test,\n}\n\nimpl TabulaSource {\n    pub fn cards_file(\u0026self) -\u003e \u0026'static str {\n        match self {\n            Self::Production =\u003e \"cards.toml\",\n            Self::Test =\u003e \"test-cards.toml\",\n        }\n    }\n    \n    pub fn dreamwell_file(\u0026self) -\u003e \u0026'static str {\n        match self {\n            Self::Production =\u003e \"dreamwell.toml\",\n            Self::Test =\u003e \"test-dreamwell.toml\",\n        }\n    }\n}\n```\n\n### Test Card Constant Generation\n\nParse test-cards.toml to extract card names and IDs, generate constants:\n\n```rust\npub fn generate_test_card_constants(output_dir: \u0026Path) -\u003e Result\u003c()\u003e {\n    let toml_path = tabula_dir().join(\"test-cards.toml\");\n    let raw_cards = load_test_cards(\u0026toml_path)?;\n    \n    let mut code = String::new();\n    code.push_str(\"// This file is auto-generated. Do not edit manually.\\n\\n\");\n    code.push_str(\"use core_data::BaseCardId;\\n\");\n    code.push_str(\"use uuid::Uuid;\\n\\n\");\n    \n    for card in \u0026raw_cards {\n        if let (Some(name), Some(id)) = (\u0026card.name, \u0026card.id) {\n            let const_name = name_to_const(name);  // \"Test Draw Card\" -\u003e \"TEST_DRAW_CARD\"\n            code.push_str(\u0026format!(\n                \"pub const {}: BaseCardId = BaseCardId(Uuid::from_u128(0x{}));\\n\",\n                const_name,\n                id.as_u128()\n            ));\n        }\n    }\n    \n    write_generated_file(\u0026output_dir.join(\"test_card.rs\"), \u0026code)?;\n    Ok(())\n}\n\nfn name_to_const(name: \u0026str) -\u003e String {\n    name.to_uppercase()\n        .replace(' ', \"_\")\n        .replace('-', \"_\")\n        // Remove any non-alphanumeric except underscore\n}\n```\n\n### Generated Constants Format\n\n```rust\n// test_card.rs (generated)\n// This file is auto-generated. Do not edit manually.\n\nuse core_data::BaseCardId;\nuse uuid::Uuid;\n\npub const TEST_DRAW_CARD: BaseCardId = BaseCardId(Uuid::from_u128(0xd8fe4b2a088c4a92aeb7d6d4d22fda1a));\npub const TEST_DAMAGE_CARD: BaseCardId = BaseCardId(Uuid::from_u128(0x...));\n// ...\n```\n\n## Files to Read First\n\n1. `rules_engine/tabula/test-cards.toml` - Test card definitions\n2. `rules_engine/src/tabula_ids/src/` - V1 card ID constants\n3. `rules_engine/docs/tabula/tabula_v2_design_document.md` - Test card strategy\n\n## Deliverables\n\n1. Define TabulaSource enum with Production/Test variants\n2. Add cards_file() and dreamwell_file() methods\n3. Implement generate_test_card_constants() function\n4. Generate test_card.rs with constants\n5. Export from tabula_generated/lib.rs\n\n## Out of Scope\n\n- Actually using TabulaSource in loading (done in Tabula struct task)\n- Removing is_test_card from existing code (migration milestone)\n- Production card constant generation (not needed - use UUID directly)\n\n## Acceptance Criteria\n\n- [ ] TabulaSource::Production returns \"cards.toml\"\n- [ ] TabulaSource::Test returns \"test-cards.toml\"\n- [ ] `tabula generate` creates test_card.rs\n- [ ] Each test card has a const with its UUID\n- [ ] Constant names are SCREAMING_SNAKE_CASE\n- [ ] Generated code compiles\n- [ ] `just check` passes\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:05.387699-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:05.387699-08:00","dependencies":[{"issue_id":"dr-ulj.15","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:05.388423-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.15","depends_on_id":"dr-ulj.14","type":"blocks","created_at":"2026-01-09T18:16:35.908484-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.16","title":"Implement main Tabula struct and loading","description":"## Objective\n\nImplement the main `Tabula` struct that orchestrates loading all card data and provides fast lookup by ID.\n\n## Background\n\nThe Tabula struct is the main entry point for accessing card data. It loads all cards, dreamwells, effects, and strings, building lookup maps for efficient access.\n\n## Files to Modify\n\n1. `rules_engine/src/tabula_data_v2/src/tabula_struct.rs` - Main implementation\n2. `rules_engine/src/tabula_data_v2/src/lib.rs` - Export Tabula\n\n## Implementation\n\n### Tabula Struct\n\n```rust\nuse std::collections::HashMap;\nuse std::path::Path;\nuse core_data::BaseCardId;\n\npub struct Tabula {\n    /// All standard card definitions\n    cards: HashMap\u003cBaseCardId, CardDefinition\u003e,\n    /// All dreamwell definitions\n    dreamwells: HashMap\u003cBaseCardId, DreamwellCardDefinition\u003e,\n    /// Card effects indexed by card ID\n    card_effects: HashMap\u003cBaseCardId, Vec\u003cCardEffectRow\u003e\u003e,\n    /// UI strings\n    strings: FluentStrings,\n    /// Cached ability parser\n    parser: AbilityParser,\n}\n\nimpl Tabula {\n    /// Load card data from the specified source\n    pub fn load(source: TabulaSource, base_path: \u0026Path) -\u003e Result\u003cSelf, TabulaError\u003e {\n        let parser = AbilityParser::new();\n        \n        // Load raw data\n        let cards_path = base_path.join(source.cards_file());\n        let dreamwell_path = base_path.join(source.dreamwell_file());\n        let effects_path = base_path.join(\"card-fx.toml\");\n        let strings_path = base_path.join(\"strings.ftl\");\n        \n        // Parse cards\n        let raw_cards = load_cards(\u0026cards_path)?;\n        let raw_dreamwells = load_dreamwells(\u0026dreamwell_path)?;\n        let raw_effects = load_card_effects(\u0026effects_path)?;\n        let strings = FluentStrings::load(\u0026strings_path)?;\n        \n        // Build card definitions\n        let mut cards = HashMap::new();\n        for raw in \u0026raw_cards {\n            match build_card_definition(raw, \u0026parser, \u0026cards_path) {\n                Ok(card) =\u003e { cards.insert(card.id, card); }\n                Err(e) =\u003e {\n                    // Log error but continue loading other cards\n                    eprintln!(\"Warning: Failed to build card: {}\", e);\n                }\n            }\n        }\n        \n        // Build dreamwell definitions\n        let mut dreamwells = HashMap::new();\n        for raw in \u0026raw_dreamwells {\n            match build_dreamwell_definition(raw, \u0026dreamwell_path) {\n                Ok(dw) =\u003e { dreamwells.insert(dw.id, dw); }\n                Err(e) =\u003e {\n                    eprintln!(\"Warning: Failed to build dreamwell: {}\", e);\n                }\n            }\n        }\n        \n        // Index effects by card ID\n        let mut card_effects: HashMap\u003cBaseCardId, Vec\u003cCardEffectRow\u003e\u003e = HashMap::new();\n        for effect in raw_effects {\n            card_effects\n                .entry(BaseCardId(effect.card_id))\n                .or_default()\n                .push(effect);\n        }\n        \n        Ok(Self {\n            cards,\n            dreamwells,\n            card_effects,\n            strings,\n            parser,\n        })\n    }\n    \n    /// Get a card definition by ID\n    pub fn card(\u0026self, id: BaseCardId) -\u003e Option\u003c\u0026CardDefinition\u003e {\n        self.cards.get(\u0026id)\n    }\n    \n    /// Get a dreamwell definition by ID\n    pub fn dreamwell(\u0026self, id: BaseCardId) -\u003e Option\u003c\u0026DreamwellCardDefinition\u003e {\n        self.dreamwells.get(\u0026id)\n    }\n    \n    /// Get card effects for a card\n    pub fn effects(\u0026self, id: BaseCardId) -\u003e \u0026[CardEffectRow] {\n        self.card_effects.get(\u0026id).map(|v| v.as_slice()).unwrap_or(\u0026[])\n    }\n    \n    /// Format a localized string\n    pub fn format_string(\u0026self, id: \u0026str, args: Option\u003c\u0026FluentArgs\u003e) -\u003e Result\u003cString, TabulaError\u003e {\n        self.strings.format(id, args)\n    }\n    \n    /// Get all card IDs\n    pub fn card_ids(\u0026self) -\u003e impl Iterator\u003cItem = BaseCardId\u003e + '_ {\n        self.cards.keys().copied()\n    }\n    \n    /// Get all dreamwell IDs\n    pub fn dreamwell_ids(\u0026self) -\u003e impl Iterator\u003cItem = BaseCardId\u003e + '_ {\n        self.dreamwells.keys().copied()\n    }\n}\n```\n\n## Files to Read First\n\n1. `rules_engine/src/tabula_data/src/tabula.rs` - V1 Tabula implementation\n2. `rules_engine/docs/tabula/tabula_v2_design_document.md` - Tabula struct section\n3. All previously implemented modules in tabula_data_v2\n\n## Deliverables\n\n1. Define Tabula struct with all data collections\n2. Implement load() method orchestrating all loading\n3. Implement accessor methods (card, dreamwell, effects, etc.)\n4. Handle loading errors gracefully (log and skip bad cards)\n5. Build HashMap indexes for fast lookup\n6. Export from lib.rs\n\n## Out of Scope\n\n- Android-specific loading (next task)\n- Integration with state_provider (next task)\n- Migration of existing code\n\n## Acceptance Criteria\n\n- [ ] Tabula::load() works with TabulaSource::Test and Test files\n- [ ] Tabula::load() works with TabulaSource::Production and prod files\n- [ ] card() returns correct CardDefinition for valid ID\n- [ ] dreamwell() returns correct DreamwellCardDefinition for valid ID\n- [ ] effects() returns effects for a card\n- [ ] format_string() works with loaded strings\n- [ ] Invalid cards are skipped with warning, not fatal error\n- [ ] `cargo test -p tabula_data_v2` passes\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:05.448221-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:05.448221-08:00","dependencies":[{"issue_id":"dr-ulj.16","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:05.44909-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.16","depends_on_id":"dr-ulj.15","type":"blocks","created_at":"2026-01-09T18:16:35.972448-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.17","title":"Integrate tabula_data_v2 with state_provider","description":"## Objective\n\nUpdate `state_provider` to use `tabula_data_v2` for loading card data, including Android-specific file loading.\n\n## Background\n\nThe state_provider crate is responsible for initializing game state, including loading card data. It needs to use the new tabula_data_v2 API with TabulaSource configuration.\n\n## Files to Modify\n\n1. `rules_engine/src/state_provider/Cargo.toml` - Add tabula_data_v2 dependency\n2. `rules_engine/src/state_provider/src/lib.rs` - Update Tabula loading code\n\n## Implementation\n\n### Update Cargo.toml\n\n```toml\n[dependencies]\n# Add V2 alongside V1 temporarily\ntabula_data_v2 = { path = \"../tabula_data_v2\" }\n```\n\n### Update Loading Code\n\nThe existing state_provider has platform-specific loading. Update to use V2:\n\n```rust\nuse tabula_data_v2::{Tabula, TabulaSource};\n\n/// Load tabula data for the current platform\npub fn load_tabula(streaming_assets_path: \u0026str, is_test: bool) -\u003e Result\u003cTabula, TabulaError\u003e {\n    let source = if is_test {\n        TabulaSource::Test\n    } else {\n        TabulaSource::Production\n    };\n    \n    #[cfg(not(target_os = \"android\"))]\n    {\n        let path = std::path::Path::new(streaming_assets_path).join(\"Tabula\");\n        Tabula::load(source, \u0026path)\n    }\n    \n    #[cfg(target_os = \"android\")]\n    {\n        load_tabula_android(streaming_assets_path, source)\n    }\n}\n```\n\n### Android Loading\n\nAndroid requires special asset loading. The pattern is already in state_provider:\n\n```rust\n#[cfg(target_os = \"android\")]\nfn load_tabula_android(streaming_assets_path: \u0026str, source: TabulaSource) -\u003e Result\u003cTabula, TabulaError\u003e {\n    use core_data::android_asset_read;\n    \n    // Load each file separately using android_asset_read\n    let cards_content = android_asset_read(\u0026format!(\"{}/Tabula/{}\", streaming_assets_path, source.cards_file()))?;\n    let dreamwell_content = android_asset_read(\u0026format!(\"{}/Tabula/{}\", streaming_assets_path, source.dreamwell_file()))?;\n    // etc.\n    \n    // Use from_strings() variant of Tabula::load\n    Tabula::load_from_strings(source, cards_content, dreamwell_content, ...)\n}\n```\n\n### Add Tabula::load_from_strings\n\nIn tabula_data_v2, add a method that takes string content instead of file paths:\n\n```rust\nimpl Tabula {\n    /// Load from string content (for Android or testing)\n    pub fn load_from_strings(\n        source: TabulaSource,\n        cards_toml: String,\n        dreamwells_toml: String,\n        effects_toml: String,\n        strings_ftl: String,\n    ) -\u003e Result\u003cSelf, TabulaError\u003e {\n        // Parse directly from strings instead of reading files\n    }\n}\n```\n\n## Files to Read First\n\n1. `rules_engine/src/state_provider/src/lib.rs` - Current state provider implementation\n2. `rules_engine/src/state_provider/src/` - All state provider code\n3. `rules_engine/src/core_data/src/` - android_asset_read function\n4. `rules_engine/docs/tabula/tabula_v2_design_document.md` - Android loading section\n\n## Deliverables\n\n1. Add tabula_data_v2 dependency to state_provider\n2. Update state_provider to use V2 Tabula loading\n3. Add Tabula::load_from_strings() for Android\n4. Handle TabulaSource::Test vs Production based on context\n5. Preserve existing Android loading patterns\n\n## Out of Scope\n\n- Removing V1 tabula_data dependency (migration milestone)\n- Updating other crates to use V2\n- Changing the state_provider public API\n\n## Acceptance Criteria\n\n- [ ] state_provider compiles with tabula_data_v2\n- [ ] Desktop loading works (file-based)\n- [ ] Android loading compiles (if android target enabled)\n- [ ] TabulaSource::Test used when appropriate\n- [ ] TabulaSource::Production used for normal gameplay\n- [ ] `cargo check -p state_provider` passes\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:05.50947-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:05.50947-08:00","dependencies":[{"issue_id":"dr-ulj.17","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:05.510222-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.17","depends_on_id":"dr-ulj.16","type":"blocks","created_at":"2026-01-09T18:16:36.037817-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.18","title":"Migrate core crates from tabula_data to tabula_data_v2","description":"## Objective\n\nUpdate imports and dependencies in core game crates from `tabula_data` to `tabula_data_v2`, and remove `is_test_card` checks.\n\n## Background\n\nThis is the main migration task. Multiple crates depend on tabula_data and need their imports updated. This task covers the simpler crates that mostly just need import changes.\n\n## Affected Crates\n\n- `battle_state` - Uses CardDefinition\n- `battle_queries` - Uses card lookups\n- `battle_mutations` - Uses card data\n- `game_creation` - Creates games with cards\n- `quest_state` - Deck building with cards\n- `rules_engine` - Core game logic\n- `ai_matchup` - AI uses card data\n\n## Implementation Steps\n\n### Step 1: Update Cargo.toml files\n\nFor each affected crate, update dependencies:\n\n```toml\n# Before\ntabula_data = { path = \"../tabula_data\" }\n\n# After\ntabula_data_v2 = { path = \"../tabula_data_v2\" }\n```\n\n### Step 2: Update Imports\n\nFind and replace imports:\n\n```rust\n// Before\nuse tabula_data::{CardDefinition, Tabula};\n\n// After\nuse tabula_data_v2::{CardDefinition, Tabula};\n```\n\n### Step 3: Remove is_test_card Checks\n\nFind and remove any code checking `is_test_card`:\n\n```rust\n// Before\nif card.is_test_card { continue; }\ncards.iter().filter(|c| !c.is_test_card)\n\n// After - remove these checks entirely\n// Test cards are now in separate files, not mixed with production\n```\n\n### Step 4: Update TabulaSource Usage\n\nWhere Tabula is loaded, use appropriate TabulaSource:\n\n```rust\n// Production code\nlet tabula = Tabula::load(TabulaSource::Production, path)?;\n\n// Test code\nlet tabula = Tabula::load(TabulaSource::Test, test_path)?;\n```\n\n## Discovery Commands\n\nRun these to find all places needing updates:\n\n```bash\n# Find all tabula_data imports\ngrep -r \"use tabula_data\" src/ tests/\ngrep -r \"tabula_data::\" src/ tests/\n\n# Find is_test_card usage\ngrep -r \"is_test_card\" src/ tests/\n```\n\n## Files to Read First\n\n1. Each affected crate's `Cargo.toml`\n2. Each affected crate's source files with tabula_data imports\n3. `rules_engine/docs/tabula/tabula_v2_design_document.md` - Migration section\n\n## Deliverables\n\n1. Update Cargo.toml in all affected crates\n2. Update all import statements\n3. Remove all is_test_card checks\n4. Update any Tabula::load() calls to use TabulaSource\n5. Ensure all crates compile\n\n## Out of Scope\n\n- Display crate migration (separate task - complex)\n- Deleting tabula_data crate (cleanup milestone)\n- Save file compatibility testing (separate task)\n\n## Acceptance Criteria\n\n- [ ] All affected crates compile with tabula_data_v2\n- [ ] No remaining imports of tabula_data in affected crates\n- [ ] No remaining is_test_card references\n- [ ] `just check` passes for all affected crates\n- [ ] `cargo test --workspace` passes (may have test failures in display crate until next task)\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:05.572285-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:05.572285-08:00","dependencies":[{"issue_id":"dr-ulj.18","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:05.573073-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.18","depends_on_id":"dr-ulj.17","type":"blocks","created_at":"2026-01-09T18:16:36.103626-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.19","title":"Migrate display crate to use parser_v2 serializers","description":"## Objective\n\nMigrate the `display` crate from using `DisplayedAbility` stored data to rendering UI text on-demand using `parser_v2` serializers.\n\n## Background\n\nThis is the most complex migration task. V2 removes stored display data (`DisplayedAbility`, `displayed_abilities`, `spanned_abilities`). Instead, UI text is rendered on-demand using the serializer system from `parser_v2/src/serializer`.\n\n## Files to Modify\n\n1. `rules_engine/src/display/Cargo.toml` - Add parser_v2 dependency\n2. All files in `rules_engine/src/display/src/` that use DisplayedAbility\n\n## Migration Pattern\n\n### Before (V1)\n```rust\nuse tabula_data::DisplayedAbility;\n\n// Access pre-computed display text\nlet displayed: \u0026DisplayedAbility = card.displayed_abilities.get(0)?;\nshow_text(\u0026displayed.text);\n```\n\n### After (V2)\n```rust\nuse parser_v2::serializer::ability_serializer;\n\n// Render text on demand\nlet ability = \u0026card.abilities[0];\nlet serialized = ability_serializer::serialize_ability(ability);\nshow_text(\u0026serialized.text);\n// serialized.variables contains VariableBindings for {placeholder} substitution\n```\n\n## Available Serializers\n\nFrom `parser_v2/src/serializer/`:\n\n- `ability_serializer::serialize_ability(\u0026ability)` - Full ability text\n- `effect_serializer::serialize_effect(\u0026effect, \u0026mut bindings)` - Effect text only\n- `predicate_serializer::serialize_predicate(\u0026predicate, \u0026mut bindings)` - Target labels (\"an ally\")\n- `trigger_serializer::serialize_trigger_event(\u0026trigger, \u0026mut bindings)` - Trigger text\n- `cost_serializer::serialize_cost(\u0026cost, \u0026mut bindings)` - Cost text\n\n## Discovery Commands\n\n```bash\n# Find DisplayedAbility usage\ngrep -r \"DisplayedAbility\" src/display/\ngrep -r \"displayed_abilities\" src/display/\ngrep -r \"spanned_abilities\" src/display/\n```\n\n## Implementation Steps\n\n1. Add `parser_v2` to display crate dependencies\n2. Update tabula_data import to tabula_data_v2\n3. Find each DisplayedAbility usage\n4. Replace with appropriate serializer call\n5. Handle VariableBindings for placeholder substitution\n\n## Variable Bindings\n\nThe serializers return `SerializedAbility` with:\n```rust\npub struct SerializedAbility {\n    pub text: String,           // The rules text with {placeholders}\n    pub variables: VariableBindings,  // Values for the placeholders\n}\n```\n\nUse `variables` to substitute placeholders in the UI:\n```rust\nlet final_text = substitute_variables(\u0026serialized.text, \u0026serialized.variables);\n```\n\n## Files to Read First\n\n1. `rules_engine/src/display/src/` - All display crate files\n2. `rules_engine/src/parser_v2/src/serializer/` - Available serializers\n3. `rules_engine/src/parser_v2/src/serializer/ability_serializer.rs` - Main serializer\n4. `rules_engine/docs/tabula/tabula_v2_design_document.md` - UI rendering section\n\n## Deliverables\n\n1. Add parser_v2 dependency to display crate\n2. Update all DisplayedAbility usages to use serializers\n3. Remove any references to spanned_abilities\n4. Handle variable substitution for UI rendering\n5. All display functionality works with new API\n\n## Out of Scope\n\n- Changes to parser_v2 serializers\n- New UI features\n- Performance optimization\n\n## Acceptance Criteria\n\n- [ ] Display crate compiles with tabula_data_v2\n- [ ] No remaining DisplayedAbility references\n- [ ] No remaining displayed_abilities references\n- [ ] Card ability text renders correctly using serializers\n- [ ] `cargo test -p display` passes\n- [ ] `just check` passes\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:05.636897-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:05.636897-08:00","dependencies":[{"issue_id":"dr-ulj.19","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:05.637616-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.19","depends_on_id":"dr-ulj.18","type":"blocks","created_at":"2026-01-09T18:16:36.167082-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.2","title":"Update TOML files to parser_v2 ability syntax","description":"## Objective\n\nUpdate `test-cards.toml` and `dreamwell.toml` to use the parser_v2 ability syntax format with variable placeholders.\n\n## Background\n\nThe parser_v2 system uses a different format for card abilities. Instead of literal numbers in rules text, it uses variable placeholders that are resolved at parse time. This enables better localization and consistent formatting.\n\n## Files to Modify\n\n1. `rules_engine/tabula/test-cards.toml`\n2. `rules_engine/tabula/dreamwell.toml`\n\n## Syntax Changes\n\n### Old Format\n```toml\nrules-text = \"Draw 2.\"\n```\n\n### New Format\n```toml\nrules-text = \"Draw {cards}.\"\nvariables = \"cards = 2\"\n```\n\n### Variable Binding Syntax\n- Multiple variables: `\"cards = 2, damage = 3\"`\n- Variables in rules text use `{variable_name}` placeholder\n\n## Files to Read First\n\n1. `rules_engine/tabula/test-cards.toml` - Test cards to update\n2. `rules_engine/tabula/dreamwell.toml` - Dreamwell cards to update\n3. `rules_engine/src/parser_v2/` - Look at parser tests for syntax examples\n4. `rules_engine/docs/tabula/tabula_v2_design_document.md` - Design context\n\n## Deliverables\n\n1. Update all cards in `test-cards.toml` with numeric values in rules text to use variables\n2. Update all cards in `dreamwell.toml` similarly\n3. Add `variables` field where needed\n\n## Out of Scope\n\n- Updating `cards.toml` (production cards - higher risk, separate task)\n- Changing the parser_v2 code itself\n- Adding new test cards\n\n## Acceptance Criteria\n\n- [ ] All numeric literals in rules-text are replaced with variable placeholders\n- [ ] Each card using placeholders has a corresponding `variables` field\n- [ ] Variable names are descriptive (e.g., `cards`, `damage`, `health`, not `x`, `y`)\n- [ ] TOML files are valid and parseable\n- [ ] Run parser_v2 tests to ensure syntax is correct: `cargo test -p parser_v2`\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:04.545751-08:00","created_by":"dthurn","updated_at":"2026-01-09T21:20:55.093235-08:00","closed_at":"2026-01-09T21:20:55.093235-08:00","close_reason":"Successfully converted test-cards.toml and dreamwell.toml to parser_v2 syntax. Added validation tests. Results: cards.toml 239/239 (100%), dreamwell.toml 5/5 (100%), test-cards.toml 38/41 (92.7%). Remaining 3 failures require parser support for numbered variables (bead dr-e36). Also filed beads dr-8f7 (XLSM variables column) and dr-azr (new prevent-dissolve test card).","dependencies":[{"issue_id":"dr-ulj.2","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:04.546412-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.20","title":"Verify save file compatibility with V2 types","description":"## Objective\n\nVerify that save files remain compatible after the migration to tabula_data_v2, ensuring CardDefinition and Ability types serialize correctly.\n\n## Background\n\nSave files store game state including CardDefinition data. The migration must not break save file compatibility. CardDefinition and Ability types need correct Serialize/Deserialize derives.\n\n## Files to Verify\n\n1. `rules_engine/src/tabula_data_v2/src/card_definition.rs` - Check derives\n2. `rules_engine/src/ability_data/src/` - Ability serialization\n3. Any test save files in the project\n\n## Verification Steps\n\n### Step 1: Check Derives\n\nEnsure CardDefinition has correct derives:\n```rust\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CardDefinition {\n    // ...\n}\n```\n\n### Step 2: Test Serialization Round-Trip\n\nCreate a test that:\n1. Creates a CardDefinition\n2. Serializes to JSON\n3. Deserializes back\n4. Verifies equality\n\n```rust\n#[test]\nfn test_card_definition_roundtrip() {\n    let card = create_test_card();\n    let json = serde_json::to_string(\u0026card).unwrap();\n    let restored: CardDefinition = serde_json::from_str(\u0026json).unwrap();\n    assert_eq!(card.id, restored.id);\n    assert_eq!(card.name, restored.name);\n    // ... verify all fields\n}\n```\n\n### Step 3: Test Ability Serialization\n\nVerify Ability enum serializes correctly:\n```rust\n#[test]\nfn test_ability_roundtrip() {\n    let ability = Ability::Draw { cards: 2 };\n    let json = serde_json::to_string(\u0026ability).unwrap();\n    let restored: Ability = serde_json::from_str(\u0026json).unwrap();\n    assert_eq!(ability, restored);\n}\n```\n\n### Step 4: Test V1 Format Compatibility (if applicable)\n\nIf V1 save files exist, verify they can still be loaded:\n```rust\n#[test]\nfn test_load_v1_save_format() {\n    let v1_json = include_str!(\"../testdata/v1_save.json\");\n    let card: CardDefinition = serde_json::from_str(v1_json).unwrap();\n    // Verify basic fields loaded\n}\n```\n\n## Files to Read First\n\n1. `rules_engine/src/tabula_data_v2/src/card_definition.rs` - CardDefinition struct\n2. `rules_engine/src/ability_data/src/` - Ability types\n3. Any existing save file tests in the codebase\n\n## Deliverables\n\n1. Add Serialize/Deserialize derives if missing\n2. Write round-trip serialization tests\n3. Verify JSON format matches expected structure\n4. Document any breaking changes to save format\n\n## Out of Scope\n\n- Save file migration tools\n- New save file features\n- Compression or optimization\n\n## Acceptance Criteria\n\n- [ ] CardDefinition has Serialize, Deserialize derives\n- [ ] Ability enum serializes correctly\n- [ ] Round-trip test passes (serialize -\u003e deserialize -\u003e equal)\n- [ ] JSON format is stable and documented\n- [ ] `cargo test -p tabula_data_v2` passes\n- [ ] `cargo test --workspace` passes\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:05.698148-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:05.698148-08:00","dependencies":[{"issue_id":"dr-ulj.20","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:05.698859-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.20","depends_on_id":"dr-ulj.19","type":"blocks","created_at":"2026-01-09T18:16:36.229105-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.21","title":"Delete old crates and rename tabula_data_v2","description":"## Objective\n\nClean up the migration by deleting the old V1 crates and renaming tabula_data_v2 to tabula_data.\n\n## Background\n\nWith the migration complete, the old crates are no longer needed. This task removes them and renames the V2 crate to take over the original name.\n\n## Deletions\n\n1. Delete `rules_engine/src/tabula_data/` - V1 crate\n2. Delete `rules_engine/src/old_tabula_cli/` - V1 CLI\n3. Delete `rules_engine/tabula.json` - Legacy generated file (if exists)\n\n## Rename\n\nRename `tabula_data_v2` to `tabula_data`:\n\n1. Rename directory: `src/tabula_data_v2/` → `src/tabula_data/`\n2. Update Cargo.toml package name: `tabula_data_v2` → `tabula_data`\n3. Update workspace members in `rules_engine/Cargo.toml`\n4. Update all dependent crate Cargo.toml files\n5. Update all import statements workspace-wide\n\n## Implementation Steps\n\n### Step 1: Delete Old Crates\n\n```bash\nrm -rf src/tabula_data\nrm -rf src/old_tabula_cli\nrm -f tabula.json  # if exists\n```\n\n### Step 2: Rename V2 Directory\n\n```bash\nmv src/tabula_data_v2 src/tabula_data\n```\n\n### Step 3: Update Cargo.toml\n\nIn `src/tabula_data/Cargo.toml`:\n```toml\n[package]\nname = \"tabula_data\"  # Was: tabula_data_v2\n```\n\n### Step 4: Update Workspace\n\nIn `rules_engine/Cargo.toml`:\n- Remove `tabula_data` (old path)\n- Remove `old_tabula_cli`\n- Keep `tabula_data` (new path, formerly v2)\n\n### Step 5: Update All Imports\n\n```bash\n# Find all v2 imports\ngrep -r \"tabula_data_v2\" src/ tests/\n\n# Replace with tabula_data\n```\n\n```rust\n// Before\nuse tabula_data_v2::{Tabula, CardDefinition};\n\n// After\nuse tabula_data::{Tabula, CardDefinition};\n```\n\n### Step 6: Update All Cargo.toml\n\n```bash\n# Find all v2 dependencies\ngrep -r \"tabula_data_v2\" src/*/Cargo.toml tests/*/Cargo.toml\n```\n\n```toml\n# Before\ntabula_data_v2 = { path = \"../tabula_data_v2\" }\n\n# After\ntabula_data = { path = \"../tabula_data\" }\n```\n\n## Files to Read First\n\n1. `rules_engine/Cargo.toml` - Workspace configuration\n2. All crate Cargo.toml files\n3. Source files with tabula_data_v2 imports\n\n## Deliverables\n\n1. Delete tabula_data (V1)\n2. Delete old_tabula_cli\n3. Delete tabula.json if present\n4. Rename tabula_data_v2 to tabula_data\n5. Update all Cargo.toml files\n6. Update all import statements\n7. Verify workspace compiles\n\n## Out of Scope\n\n- Any code changes beyond import updates\n- New features\n- Performance optimization\n\n## Acceptance Criteria\n\n- [ ] No `src/tabula_data_v2/` directory exists\n- [ ] No `src/old_tabula_cli/` directory exists\n- [ ] No `tabula.json` file exists\n- [ ] `src/tabula_data/` exists with V2 code\n- [ ] Package name is `tabula_data`\n- [ ] All imports use `tabula_data` (not v2)\n- [ ] `just check` passes\n- [ ] `cargo test --workspace` passes\n- [ ] `just review` passes\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:05.760341-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:05.760341-08:00","dependencies":[{"issue_id":"dr-ulj.21","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:05.761038-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.21","depends_on_id":"dr-ulj.20","type":"blocks","created_at":"2026-01-09T18:16:36.336309-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.3","title":"Create tabula_data_v2 crate scaffolding","description":"## Objective\n\nCreate the new `tabula_data_v2` crate with proper structure and dependencies, with empty module stubs.\n\n## Background\n\nThis is the foundation crate for the new card loading system. It will eventually replace `tabula_data`. The crate needs to be set up with all required dependencies before implementing the actual functionality.\n\n## Crate Location\n\n`rules_engine/src/tabula_data_v2/`\n\n## Directory Structure to Create\n\n```\nsrc/tabula_data_v2/\n├── Cargo.toml\n├── src/\n│   ├── lib.rs                      # Module declarations only\n│   ├── card_definition_raw.rs      # Unified raw card definition type\n│   ├── card_definition_builder.rs  # Builds final types from raw\n│   ├── card_definition.rs          # Final CardDefinition struct\n│   ├── dreamwell_definition.rs     # DreamwellCardDefinition struct\n│   ├── dreamsign_definition.rs     # Future: DreamsignCardDefinition (stub)\n│   ├── card_effect_row.rs          # CardEffectRow (from card-fx.toml)\n│   ├── card_list_row.rs            # CardListRow (from card-lists.toml)\n│   ├── fluent_loader.rs            # Fluent string loading from .ftl\n│   ├── ability_parser.rs           # parser_v2 integration wrapper\n│   ├── toml_loader.rs              # TOML file loading utilities\n│   ├── tabula_struct.rs            # Main Tabula struct\n│   └── tabula_error.rs             # Error types with location info\n```\n\n## Cargo.toml Dependencies\n\n```toml\n[package]\nname = \"tabula_data_v2\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[dependencies]\n# Internal\nability_data = { path = \"../ability_data\" }\ncore_data = { path = \"../core_data\" }\nparser_v2 = { path = \"../parser_v2\" }\n\n# External\nanyhow = \"1\"\nfluent = \"0.16\"\nfluent-bundle = \"0.15\"\nserde = { version = \"1\", features = [\"derive\"] }\nserde_json = \"1\"\ntoml = \"0.8\"\nuuid = { version = \"1\", features = [\"v4\", \"serde\"] }\nthiserror = \"1\"\nunic-langid = \"0.9\"\n```\n\n## Files to Read First\n\n1. `rules_engine/Cargo.toml` - Workspace configuration\n2. `rules_engine/src/tabula_data/Cargo.toml` - Reference for V1 dependencies\n3. `rules_engine/docs/tabula/tabula_v2_design_document.md` - Crate structure section\n\n## Deliverables\n\n1. Create `src/tabula_data_v2/` directory\n2. Create `Cargo.toml` with all dependencies\n3. Create `src/lib.rs` with module declarations\n4. Create empty stub files for each module (just `//! Module description` comment)\n5. Add crate to workspace in `rules_engine/Cargo.toml`\n\n## Module Stubs\n\nEach module file should contain just a doc comment placeholder:\n\n```rust\n//! Card definition raw types for TOML deserialization.\n//!\n//! This module will contain CardDefinitionRaw and TomlValue types.\n```\n\n## Out of Scope\n\n- Implementing any actual functionality\n- Adding tests\n- Using the crate from other crates\n\n## Acceptance Criteria\n\n- [ ] Crate compiles with `cargo check -p tabula_data_v2`\n- [ ] All module files exist with doc comment stubs\n- [ ] Crate is listed in workspace members\n- [ ] Dependencies resolve correctly\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:04.607519-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:04.607519-08:00","dependencies":[{"issue_id":"dr-ulj.3","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:04.608251-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.3","depends_on_id":"dr-ulj.1","type":"blocks","created_at":"2026-01-09T18:16:34.036224-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.3","depends_on_id":"dr-ulj.2","type":"blocks","created_at":"2026-01-09T18:16:34.100846-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.4","title":"Implement CardDefinitionRaw and TomlValue types","description":"## Objective\n\nImplement the `CardDefinitionRaw` struct and `TomlValue` enum for deserializing cards from TOML files.\n\n## Background\n\nCardDefinitionRaw is a unified struct with all optional fields that can represent any card type (standard cards, dreamwells, etc.). This is the first step in the TOML loading pipeline.\n\n## Files to Modify\n\n1. `rules_engine/src/tabula_data_v2/src/card_definition_raw.rs`\n\n## Implementation\n\n### CardDefinitionRaw Struct\n\n```rust\nuse serde::Deserialize;\nuse uuid::Uuid;\n\n#[derive(Debug, Clone, Deserialize)]\n#[serde(rename_all = \"kebab-case\")]\npub struct CardDefinitionRaw {\n    pub id: Option\u003cUuid\u003e,\n    pub name: Option\u003cString\u003e,\n    pub card_type: Option\u003cString\u003e,\n    pub subtype: Option\u003cString\u003e,\n    pub energy_cost: Option\u003cTomlValue\u003e,\n    pub spark: Option\u003ci32\u003e,\n    pub phase: Option\u003ci32\u003e,\n    pub rules_text: Option\u003cString\u003e,\n    pub prompts: Option\u003cString\u003e,\n    pub variables: Option\u003cString\u003e,\n    pub image_number: Option\u003ci64\u003e,\n    pub rarity: Option\u003cString\u003e,\n    pub card_number: Option\u003ci32\u003e,\n    pub energy_produced: Option\u003ci32\u003e,\n    pub is_fast: Option\u003cbool\u003e,\n}\n```\n\n### TomlValue Enum\n\n```rust\n#[derive(Debug, Clone)]\npub enum TomlValue {\n    Integer(i32),\n    String(String),\n}\n```\n\nImplement custom `Deserialize` for `TomlValue` to handle both integer and string TOML values:\n\n```rust\nimpl\u003c'de\u003e Deserialize\u003c'de\u003e for TomlValue {\n    fn deserialize\u003cD\u003e(deserializer: D) -\u003e Result\u003cSelf, D::Error\u003e\n    where\n        D: serde::Deserializer\u003c'de\u003e,\n    {\n        // Use serde_json::Value or implement visitor to handle both types\n    }\n}\n```\n\n## Files to Read First\n\n1. `rules_engine/tabula/cards.toml` - See actual card field names and formats\n2. `rules_engine/tabula/dreamwell.toml` - Dreamwell-specific fields\n3. `rules_engine/tabula/test-cards.toml` - Test card format\n4. `rules_engine/src/tabula_data/src/card_definitions/base_card_definition_raw.rs` - V1 reference\n5. `rules_engine/docs/tabula/tabula_v2_design_document.md` - CardDefinitionRaw section\n\n## Deliverables\n\n1. Implement `CardDefinitionRaw` with all optional fields\n2. Implement `TomlValue` enum with custom deserializer\n3. Add `#[serde(rename_all = \"kebab-case\")]` for TOML field naming\n4. Export types from `lib.rs`\n\n## Out of Scope\n\n- Loading from files (next task)\n- Error types (next task)\n- Building final CardDefinition from raw\n\n## Acceptance Criteria\n\n- [ ] `CardDefinitionRaw` can deserialize a standard card from TOML string\n- [ ] `CardDefinitionRaw` can deserialize a dreamwell card from TOML string\n- [ ] `TomlValue` handles both `energy_cost = 2` and `energy_cost = \"*\"`\n- [ ] Types are exported from crate root\n- [ ] `cargo check -p tabula_data_v2` passes\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:04.671308-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:04.671308-08:00","dependencies":[{"issue_id":"dr-ulj.4","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:04.672103-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.4","depends_on_id":"dr-ulj.3","type":"blocks","created_at":"2026-01-09T18:16:34.162099-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.5","title":"Implement TabulaError and TOML loading infrastructure","description":"## Objective\n\nCreate the error types and TOML loading functions for loading card definitions from files.\n\n## Background\n\nThis task builds on the CardDefinitionRaw types to provide file loading capabilities with proper error handling that includes location information.\n\n## Files to Modify\n\n1. `rules_engine/src/tabula_data_v2/src/tabula_error.rs` - Error types\n2. `rules_engine/src/tabula_data_v2/src/toml_loader.rs` - Loading functions\n3. `rules_engine/src/tabula_data_v2/src/lib.rs` - Export new types\n\n## Implementation\n\n### TabulaError Type\n\n```rust\nuse std::path::PathBuf;\nuse thiserror::Error;\nuse uuid::Uuid;\n\n#[derive(Debug, Error)]\npub enum TabulaError {\n    #[error(\"IO error reading {path}: {source}\")]\n    IoError { path: PathBuf, source: std::io::Error },\n    \n    #[error(\"TOML parse error in {file}: {message}\")]\n    TomlParse { file: PathBuf, message: String },\n    \n    #[error(\"Missing required field '{field}' in {file} for card {card_id:?}\")]\n    MissingField { file: PathBuf, card_id: Option\u003cUuid\u003e, field: \u0026'static str },\n    \n    #[error(\"Unexpected field '{field}' in {file} for card {card_id:?}\")]\n    UnexpectedField { file: PathBuf, card_id: Option\u003cUuid\u003e, field: String },\n    \n    #[error(\"Ability parse error for card '{card_name}' in {file}: {message}\")]\n    AbilityParse { file: PathBuf, card_name: String, message: String },\n    \n    #[error(\"Fluent error for message '{message_id}' in {file}: {message}\")]\n    FluentError { file: PathBuf, message_id: String, message: String },\n}\n```\n\n### TOML Wrapper Structs\n\n```rust\n#[derive(Debug, Deserialize)]\npub struct CardsFile {\n    pub cards: Vec\u003cCardDefinitionRaw\u003e,\n}\n\n#[derive(Debug, Deserialize)]\npub struct TestCardsFile {\n    #[serde(rename = \"test-cards\")]\n    pub test_cards: Vec\u003cCardDefinitionRaw\u003e,\n}\n\n#[derive(Debug, Deserialize)]\npub struct DreamwellFile {\n    pub dreamwells: Vec\u003cCardDefinitionRaw\u003e,\n}\n```\n\n### Loading Functions\n\n```rust\npub fn load_cards\u003cP: AsRef\u003cPath\u003e\u003e(path: P) -\u003e Result\u003cVec\u003cCardDefinitionRaw\u003e, TabulaError\u003e;\npub fn load_test_cards\u003cP: AsRef\u003cPath\u003e\u003e(path: P) -\u003e Result\u003cVec\u003cCardDefinitionRaw\u003e, TabulaError\u003e;\npub fn load_dreamwells\u003cP: AsRef\u003cPath\u003e\u003e(path: P) -\u003e Result\u003cVec\u003cCardDefinitionRaw\u003e, TabulaError\u003e;\n\n// Internal helper\nfn load_toml_file\u003cT: DeserializeOwned, P: AsRef\u003cPath\u003e\u003e(path: P) -\u003e Result\u003cT, TabulaError\u003e;\n```\n\n## Files to Read First\n\n1. `rules_engine/tabula/cards.toml` - See `[[cards]]` structure\n2. `rules_engine/tabula/test-cards.toml` - See `[[test-cards]]` structure  \n3. `rules_engine/tabula/dreamwell.toml` - See `[[dreamwells]]` structure\n4. `rules_engine/src/tabula_data/src/tabula_table.rs` - V1 error handling reference\n5. `rules_engine/docs/tabula/tabula_v2_design_document.md` - Error handling section\n\n## Deliverables\n\n1. Implement `TabulaError` enum with thiserror derives\n2. Implement wrapper structs for each TOML file type\n3. Implement loading functions that read files and return Vec\u003cCardDefinitionRaw\u003e\n4. Add unit tests using inline TOML strings (no actual file I/O)\n5. Export types from lib.rs\n\n## Testing\n\nAdd tests in the module:\n```rust\n#[cfg(test)]\nmod tests {\n    #[test]\n    fn test_parse_single_card() {\n        let toml = r#\"\n        [[cards]]\n        name = \"Test Card\"\n        id = \"d8fe4b2a-088c-4a92-aeb7-d6d4d22fda1a\"\n        energy-cost = 2\n        \"#;\n        // ... assert parsing works\n    }\n}\n```\n\n## Out of Scope\n\n- Actually using the loaded data\n- Building CardDefinition from raw\n- Loading FTL files\n\n## Acceptance Criteria\n\n- [ ] TabulaError provides helpful error messages with file paths\n- [ ] Loading functions work with the actual TOML file format\n- [ ] Unit tests pass for inline TOML parsing\n- [ ] Wrapper structs handle the array-of-tables pattern\n- [ ] `cargo test -p tabula_data_v2` passes\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:04.732715-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:04.732715-08:00","dependencies":[{"issue_id":"dr-ulj.5","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:04.73347-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.5","depends_on_id":"dr-ulj.4","type":"blocks","created_at":"2026-01-09T18:16:34.227973-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.6","title":"Implement FluentStrings loader","description":"## Objective\n\nImplement the `FluentStrings` struct for loading and formatting localized strings from FTL (Fluent) files.\n\n## Background\n\nThe Fluent localization system is used for UI strings and card text formatting. This module provides a wrapper around the fluent crate for easy string loading and formatting with variable substitution.\n\n## Files to Modify\n\n1. `rules_engine/src/tabula_data_v2/src/fluent_loader.rs`\n2. `rules_engine/src/tabula_data_v2/src/lib.rs` - Export FluentStrings\n\n## Implementation\n\n### FluentStrings Struct\n\n```rust\nuse fluent::{FluentBundle, FluentResource, FluentArgs, FluentValue};\nuse unic_langid::LanguageIdentifier;\n\npub struct FluentStrings {\n    bundle: FluentBundle\u003cFluentResource\u003e,\n}\n\nimpl FluentStrings {\n    /// Load Fluent strings from an FTL file\n    pub fn load\u003cP: AsRef\u003cPath\u003e\u003e(path: P) -\u003e Result\u003cSelf, TabulaError\u003e {\n        let content = std::fs::read_to_string(\u0026path)?;\n        Self::from_string(content, path.as_ref().to_path_buf())\n    }\n    \n    /// Load Fluent strings from a string (for testing)\n    pub fn from_string(content: String, source_path: PathBuf) -\u003e Result\u003cSelf, TabulaError\u003e {\n        let langid: LanguageIdentifier = \"en-US\".parse().expect(\"valid langid\");\n        let mut bundle = FluentBundle::new(vec![langid]);\n        \n        let resource = FluentResource::try_new(content)\n            .map_err(|_| TabulaError::FluentError { \n                file: source_path, \n                message_id: \"\".to_string(),\n                message: \"Failed to parse FTL file\".to_string() \n            })?;\n        \n        bundle.add_resource(resource)?;\n        Ok(Self { bundle })\n    }\n    \n    /// Format a message with optional arguments\n    pub fn format(\u0026self, id: \u0026str, args: Option\u003c\u0026FluentArgs\u003e) -\u003e Result\u003cString, TabulaError\u003e {\n        let msg = self.bundle.get_message(id)?;\n        let pattern = msg.value()?;\n        let mut errors = vec![];\n        let result = self.bundle.format_pattern(pattern, args, \u0026mut errors);\n        // Handle errors...\n        Ok(result.to_string())\n    }\n    \n    /// Check if a message ID exists\n    pub fn has_message(\u0026self, id: \u0026str) -\u003e bool {\n        self.bundle.get_message(id).is_some()\n    }\n}\n```\n\n### FluentArgs Helper\n\n```rust\n/// Create FluentArgs from key-value pairs\npub fn make_args(pairs: \u0026[(\u0026str, \u0026str)]) -\u003e FluentArgs\u003c'_\u003e {\n    let mut args = FluentArgs::new();\n    for (key, value) in pairs {\n        args.set(*key, FluentValue::from(*value));\n    }\n    args\n}\n```\n\n## Files to Read First\n\n1. `rules_engine/tabula/strings.ftl` - Created in milestone 1 (or `strings.toml` for reference)\n2. Fluent crate documentation: https://docs.rs/fluent/latest/fluent/\n3. `rules_engine/docs/tabula/tabula_v2_design_document.md` - Fluent section\n4. `rules_engine/src/tabula_data/src/localized_strings.rs` - V1 reference\n\n## Deliverables\n\n1. Implement `FluentStrings` struct with load/format methods\n2. Handle missing messages gracefully with TabulaError\n3. Add helper function for creating FluentArgs\n4. Write unit tests with inline FTL content\n5. Export from lib.rs\n\n## Testing\n\n```rust\n#[cfg(test)]\nmod tests {\n    #[test]\n    fn test_format_simple_message() {\n        let ftl = \"hello = Hello World\";\n        let strings = FluentStrings::from_string(ftl.to_string(), \"test.ftl\".into())?;\n        assert_eq!(strings.format(\"hello\", None)?, \"Hello World\");\n    }\n    \n    #[test]\n    fn test_format_with_args() {\n        let ftl = \"greeting = Hello { $name }!\";\n        let strings = FluentStrings::from_string(ftl.to_string(), \"test.ftl\".into())?;\n        let args = make_args(\u0026[(\"name\", \"Player\")]);\n        assert_eq!(strings.format(\"greeting\", Some(\u0026args))?, \"Hello Player!\");\n    }\n}\n```\n\n## Out of Scope\n\n- Loading multiple FTL files\n- Locale fallback/selection\n- Complex Fluent features (selectors, etc.)\n\n## Acceptance Criteria\n\n- [ ] FluentStrings can load from file path\n- [ ] FluentStrings can load from string content\n- [ ] format() returns formatted strings with variable substitution\n- [ ] Missing messages return appropriate TabulaError\n- [ ] Unit tests pass\n- [ ] `cargo test -p tabula_data_v2` passes\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:04.79352-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:04.79352-08:00","dependencies":[{"issue_id":"dr-ulj.6","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:04.794185-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.6","depends_on_id":"dr-ulj.5","type":"blocks","created_at":"2026-01-09T18:16:34.33756-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.7","title":"Implement AbilityParser wrapper for parser_v2","description":"## Objective\n\nCreate the `AbilityParser` struct that wraps parser_v2 for parsing card abilities from rules text and variables.\n\n## Background\n\nCard abilities need to be parsed at runtime from the TOML rules_text and variables fields. The AbilityParser caches the parser instance for performance and provides a clean API for parsing abilities.\n\n## Files to Modify\n\n1. `rules_engine/src/tabula_data_v2/src/ability_parser.rs`\n2. `rules_engine/src/tabula_data_v2/src/lib.rs` - Export AbilityParser\n\n## Implementation\n\n### AbilityParser Struct\n\n```rust\nuse parser_v2::ability_parser;\nuse ability_data::Ability;\n\npub struct AbilityParser {\n    // Cached parser instance - parser_v2 parser can be reused\n}\n\nimpl AbilityParser {\n    pub fn new() -\u003e Self {\n        Self { /* initialize parser */ }\n    }\n    \n    /// Parse abilities from rules text and variable bindings\n    /// \n    /// # Arguments\n    /// * `rules_text` - The card's rules text (e.g., \"Draw {cards}.\")\n    /// * `variables` - Variable bindings (e.g., \"cards = 2\")\n    /// * `card_name` - For error messages\n    /// \n    /// # Returns\n    /// Vec\u003cAbility\u003e - Parsed abilities\n    pub fn parse(\n        \u0026self,\n        rules_text: \u0026str,\n        variables: Option\u003c\u0026str\u003e,\n        card_name: \u0026str,\n    ) -\u003e Result\u003cVec\u003cAbility\u003e, TabulaError\u003e {\n        // 1. Parse variable bindings if present\n        // 2. Lex the rules text\n        // 3. Resolve variables in tokens\n        // 4. Parse abilities from tokens\n        // 5. Return parsed abilities or wrap error with card context\n    }\n    \n    /// Parse variable bindings from string format\n    /// Format: \"name = value, name2 = value2\"\n    fn parse_variables(variables: \u0026str) -\u003e Result\u003cHashMap\u003cString, i32\u003e, String\u003e {\n        // Split by comma, then by equals\n    }\n}\n\nimpl Default for AbilityParser {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n```\n\n## Files to Read First\n\n1. `rules_engine/src/parser_v2/src/ability_parser.rs` - Main parser implementation\n2. `rules_engine/src/parser_v2/src/lexer.rs` - How tokenization works\n3. `rules_engine/src/parser_v2/src/variable_resolver.rs` - Variable resolution\n4. `rules_engine/tests/parser_v2_tests/` - Examples of parsing\n5. `rules_engine/docs/tabula/tabula_v2_design_document.md` - AbilityParser section\n\n## Variable Resolution\n\nThe parser_v2 lexer produces tokens like `{cards}`. Before parsing, these need to be resolved to actual values using the variable bindings.\n\nExample flow:\n1. Input: rules_text=\"Draw {cards}.\", variables=\"cards = 2\"\n2. Parse variables: {\"cards\": 2}\n3. Lex: [Word(\"Draw\"), Variable(\"cards\"), Period]\n4. Resolve: [Word(\"Draw\"), Number(2), Period]\n5. Parse: Ability::Draw { cards: 2 }\n\n## Deliverables\n\n1. Implement AbilityParser with cached parser\n2. Implement parse() method with variable resolution\n3. Implement parse_variables() helper\n4. Include card name in error messages via TabulaError::AbilityParse\n5. Write unit tests parsing sample ability text\n6. Export from lib.rs\n\n## Testing\n\n```rust\n#[cfg(test)]\nmod tests {\n    #[test]\n    fn test_parse_draw_ability() {\n        let parser = AbilityParser::new();\n        let abilities = parser.parse(\n            \"Draw {cards}.\",\n            Some(\"cards = 2\"),\n            \"Test Card\"\n        )?;\n        assert_eq!(abilities.len(), 1);\n        // Assert ability is Draw with cards=2\n    }\n    \n    #[test]\n    fn test_parse_no_variables() {\n        let parser = AbilityParser::new();\n        let abilities = parser.parse(\n            \"This card has no abilities.\",\n            None,\n            \"Test Card\"\n        )?;\n        // Might return empty or flavor text\n    }\n}\n```\n\n## Out of Scope\n\n- Modifying parser_v2 internals\n- UI rendering (uses serializers, separate module)\n- Caching parsed abilities (done in Tabula struct)\n\n## Acceptance Criteria\n\n- [ ] AbilityParser can parse abilities from rules text\n- [ ] Variable placeholders are correctly resolved\n- [ ] Error messages include card name for debugging\n- [ ] Parser instance is reused (not recreated per parse)\n- [ ] Unit tests pass\n- [ ] `cargo test -p tabula_data_v2` passes\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:04.85804-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:04.85804-08:00","dependencies":[{"issue_id":"dr-ulj.7","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:04.85877-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.7","depends_on_id":"dr-ulj.6","type":"blocks","created_at":"2026-01-09T18:16:34.402208-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.8","title":"Implement CardDefinition builder","description":"## Objective\n\nImplement the card definition builder that converts `CardDefinitionRaw` into final `CardDefinition` structs with parsed abilities.\n\n## Background\n\nThe builder validates required fields, converts string enum values to proper types, and uses AbilityParser to parse abilities. It's the core transformation from raw TOML data to usable card objects.\n\n## Files to Modify\n\n1. `rules_engine/src/tabula_data_v2/src/card_definition.rs` - CardDefinition struct\n2. `rules_engine/src/tabula_data_v2/src/card_definition_builder.rs` - Builder logic\n3. `rules_engine/src/tabula_data_v2/src/lib.rs` - Export types\n\n## Implementation\n\n### CardDefinition Struct\n\n```rust\nuse ability_data::Ability;\nuse core_data::{CardType, Rarity, BaseCardId};\nuse uuid::Uuid;\n\n#[derive(Debug, Clone)]\npub struct CardDefinition {\n    pub id: BaseCardId,\n    pub name: String,\n    pub card_type: CardType,\n    pub subtype: Option\u003cString\u003e,\n    pub energy_cost: Option\u003ci32\u003e,  // None for modal cards (was \"*\")\n    pub spark: Option\u003ci32\u003e,\n    pub phase: Option\u003ci32\u003e,\n    pub abilities: Vec\u003cAbility\u003e,\n    pub image_number: Option\u003ci64\u003e,\n    pub rarity: Rarity,\n    pub card_number: Option\u003ci32\u003e,\n    pub is_fast: bool,\n}\n```\n\nNote: No `is_test_card` field. No `displayed_abilities` - UI uses serializers.\n\n### Builder Function\n\n```rust\npub fn build_card_definition(\n    raw: \u0026CardDefinitionRaw,\n    parser: \u0026AbilityParser,\n    source_file: \u0026Path,\n) -\u003e Result\u003cCardDefinition, TabulaError\u003e {\n    // 1. Validate required fields exist\n    let id = raw.id.ok_or_else(|| TabulaError::MissingField {\n        file: source_file.to_path_buf(),\n        card_id: None,\n        field: \"id\",\n    })?;\n    \n    let name = raw.name.clone().ok_or_else(|| TabulaError::MissingField {\n        file: source_file.to_path_buf(),\n        card_id: Some(id),\n        field: \"name\",\n    })?;\n    \n    // 2. Convert string enums to proper types\n    let card_type = parse_card_type(\u0026raw.card_type, \u0026id, source_file)?;\n    let rarity = parse_rarity(\u0026raw.rarity, \u0026id, source_file)?;\n    \n    // 3. Handle energy_cost (TomlValue -\u003e Option\u003ci32\u003e)\n    let energy_cost = match \u0026raw.energy_cost {\n        Some(TomlValue::Integer(n)) =\u003e Some(*n),\n        Some(TomlValue::String(s)) if s == \"*\" =\u003e None,\n        Some(TomlValue::String(s)) =\u003e return Err(...),\n        None =\u003e None,\n    };\n    \n    // 4. Parse abilities if rules_text exists\n    let abilities = if let Some(rules_text) = \u0026raw.rules_text {\n        parser.parse(rules_text, raw.variables.as_deref(), \u0026name)?\n    } else {\n        vec![]\n    };\n    \n    Ok(CardDefinition { ... })\n}\n```\n\n### String Enum Parsers\n\n```rust\nfn parse_card_type(s: \u0026Option\u003cString\u003e, card_id: \u0026Uuid, file: \u0026Path) -\u003e Result\u003cCardType, TabulaError\u003e;\nfn parse_rarity(s: \u0026Option\u003cString\u003e, card_id: \u0026Uuid, file: \u0026Path) -\u003e Result\u003cRarity, TabulaError\u003e;\n```\n\n## Files to Read First\n\n1. `rules_engine/src/core_data/src/` - CardType, Rarity enum definitions\n2. `rules_engine/src/tabula_data/src/card_definitions/card_definition.rs` - V1 reference\n3. `rules_engine/src/tabula_data/src/card_definitions/card_definition_builder.rs` - V1 builder\n4. `rules_engine/docs/tabula/tabula_v2_design_document.md` - Card building section\n\n## Deliverables\n\n1. Define CardDefinition struct (no is_test_card, no displayed_abilities)\n2. Implement build_card_definition() function\n3. Implement string-to-enum parsing helpers\n4. Validate required fields with descriptive errors\n5. Write unit tests\n6. Export from lib.rs\n\n## Out of Scope\n\n- DreamwellCardDefinition (next task)\n- Building from actual files (done in Tabula struct)\n- Caching built definitions\n\n## Acceptance Criteria\n\n- [ ] CardDefinition struct matches design doc\n- [ ] Builder validates all required fields\n- [ ] String enums (card_type, rarity) parse correctly\n- [ ] TomlValue energy_cost converts to Option\u003ci32\u003e\n- [ ] Abilities are parsed via AbilityParser\n- [ ] Error messages include card ID and file path\n- [ ] `cargo test -p tabula_data_v2` passes\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:04.920103-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:04.920103-08:00","dependencies":[{"issue_id":"dr-ulj.8","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:04.920827-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.8","depends_on_id":"dr-ulj.7","type":"blocks","created_at":"2026-01-09T18:16:34.473645-08:00","created_by":"dthurn"}]}
{"id":"dr-ulj.9","title":"Implement DreamwellCardDefinition type","description":"## Objective\n\nImplement `DreamwellCardDefinition` struct and builder for dreamwell-type cards which have special validation requirements.\n\n## Background\n\nDreamwell cards are a special card type that produces energy. They have a required `energy_produced` field and different validation rules than standard cards.\n\n## Files to Modify\n\n1. `rules_engine/src/tabula_data_v2/src/dreamwell_definition.rs`\n2. `rules_engine/src/tabula_data_v2/src/dreamsign_definition.rs` - Stub only\n3. `rules_engine/src/tabula_data_v2/src/lib.rs` - Export types\n\n## Implementation\n\n### DreamwellCardDefinition Struct\n\n```rust\nuse core_data::BaseCardId;\n\n#[derive(Debug, Clone)]\npub struct DreamwellCardDefinition {\n    pub id: BaseCardId,\n    pub name: String,\n    pub energy_produced: i32,  // Required for dreamwells\n    pub image_number: Option\u003ci64\u003e,\n    pub card_number: Option\u003ci32\u003e,\n}\n```\n\n### Builder Function\n\n```rust\npub fn build_dreamwell_definition(\n    raw: \u0026CardDefinitionRaw,\n    source_file: \u0026Path,\n) -\u003e Result\u003cDreamwellCardDefinition, TabulaError\u003e {\n    // 1. Validate required fields\n    let id = raw.id.ok_or_else(|| TabulaError::MissingField {\n        file: source_file.to_path_buf(),\n        card_id: None,\n        field: \"id\",\n    })?;\n    \n    let name = raw.name.clone().ok_or_else(|| ...)?;\n    \n    // 2. Require energy_produced for dreamwells\n    let energy_produced = raw.energy_produced.ok_or_else(|| TabulaError::MissingField {\n        file: source_file.to_path_buf(),\n        card_id: Some(id),\n        field: \"energy_produced\",\n    })?;\n    \n    Ok(DreamwellCardDefinition {\n        id: BaseCardId(id),\n        name,\n        energy_produced,\n        image_number: raw.image_number,\n        card_number: raw.card_number,\n    })\n}\n```\n\n### DreamsignCardDefinition Stub\n\n```rust\n//! Dreamsign card definition type.\n//!\n//! This is a placeholder for future dreamsign card support.\n//! Dreamsigns are special cards with unique rules.\n\n// TODO: Implement when dreamsign cards are added to the game\n```\n\n## Files to Read First\n\n1. `rules_engine/tabula/dreamwell.toml` - Dreamwell card format\n2. `rules_engine/tabula/test-dreamwell.toml` - Test dreamwell format\n3. `rules_engine/src/tabula_data/src/card_definitions/dreamwell_card_definition.rs` - V1 reference\n4. `rules_engine/docs/tabula/tabula_v2_design_document.md` - Dreamwell section\n\n## Deliverables\n\n1. Define DreamwellCardDefinition struct\n2. Implement build_dreamwell_definition() function\n3. Require energy_produced field with clear error if missing\n4. Create dreamsign_definition.rs stub file\n5. Write unit tests\n6. Export from lib.rs\n\n## Out of Scope\n\n- Full dreamsign implementation (just stub)\n- Abilities on dreamwell cards (they don't have them)\n- UI rendering\n\n## Acceptance Criteria\n\n- [ ] DreamwellCardDefinition has required energy_produced field\n- [ ] Builder fails with clear error if energy_produced is missing\n- [ ] Can build dreamwell from TOML data\n- [ ] dreamsign_definition.rs exists as placeholder\n- [ ] No is_test_card field\n- [ ] `cargo test -p tabula_data_v2` passes\n\n## Validation\n\nRun `just review` to validate changes, then commit with a 5-10 word message without asking for confirmation.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T18:16:04.97886-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:16:04.97886-08:00","dependencies":[{"issue_id":"dr-ulj.9","depends_on_id":"dr-ulj","type":"parent-child","created_at":"2026-01-09T18:16:04.979544-08:00","created_by":"dthurn"},{"issue_id":"dr-ulj.9","depends_on_id":"dr-ulj.8","type":"blocks","created_at":"2026-01-09T18:16:34.533673-08:00","created_by":"dthurn"}]}
{"id":"dr-wcq","title":"LLMC v2: TMUX Reliable Communication","description":"## Overview\nImplement reliable input sending to TMUX sessions with debouncing and retry logic.\n\n## Context\nThis is the most critical component of LLMC v2. TMUX send-keys can have race conditions. See `rules_engine/docs/llmc2-appendix-tmux.md` for detailed debounce timing research and implementation patterns.\n\n## Deliverables\n1. Implement `src/tmux/sender.rs`:\n   - `TmuxSender` struct with configurable timing parameters\n   - `send(\u0026self, session: \u0026str, message: \u0026str)` -\u003e Result\u003c()\u003e\n   - `send_keys_raw(\u0026self, session: \u0026str, keys: \u0026str)` -\u003e Result\u003c()\u003e\n   - `send_large_message(\u0026self, session: \u0026str, message: \u0026str)` -\u003e Result\u003c()\u003e\n\n2. Debounce timing (from research):\n   - Base delay: 500ms (configurable, can be reduced to 100ms)\n   - Per-KB delay: 100ms\n   - Maximum delay cap: 2000ms\n   - Enter retry count: 3\n   - Enter retry delay: 200ms\n\n3. Small message sending (\u003c1KB):\n   - Use `tmux send-keys -l` for literal mode\n   - Calculate debounce delay based on size\n   - Send Enter with retry logic\n\n4. Large message sending (\u003e=1KB):\n   - Write message to temp file\n   - Use `tmux load-buffer` to load from file\n   - Use `tmux paste-buffer` to paste\n   - Standard debounce and Enter\n\n5. Recovery functions:\n   - `clear_input_line(\u0026self, session: \u0026str)` -\u003e Result\u003c()\u003e (sends Ctrl-U)\n   - `detect_partial_send(\u0026self, session: \u0026str, expected: \u0026str)` -\u003e PartialSendStatus\n   - `clear_and_retry(\u0026self, session: \u0026str, message: \u0026str)` -\u003e Result\u003c()\u003e\n\n6. PartialSendStatus enum:\n   - NoInput\n   - Partial { received: usize, expected: usize }\n   - Complete\n   - Unknown\n\n## Out of Scope\n- State detection (next task)\n- High-level send verification (handled in error recovery task)\n\n## Testing Instructions\n- Run `cargo test tmux::sender`\n- Manually test with various message sizes\n- Verify large messages use load-buffer method\n\n## Acceptance Criteria\n- [ ] Small messages sent with correct debounce\n- [ ] Large messages use load-buffer method\n- [ ] Partial send detection works\n- [ ] Ctrl-U clears input line\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nAfter completing this task, output a \"Manual Testing Instructions\" section describing how to manually verify the work.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T06:55:18.450504-08:00","created_by":"dthurn","updated_at":"2026-01-10T11:19:21.931872-08:00","closed_at":"2026-01-10T11:19:21.931872-08:00","close_reason":"Closed","dependencies":[{"issue_id":"dr-wcq","depends_on_id":"dr-sga","type":"blocks","created_at":"2026-01-10T06:58:39.25157-08:00","created_by":"dthurn"}]}
{"id":"dr-yu9","title":"LLMC v2: Commands - start and message","description":"## Overview\nImplement the `llmc start` and `llmc message` commands for sending work to workers.\n\n## Context\n`start` assigns a new task to an idle worker. `message` sends follow-up communication to a worker. See `rules_engine/docs/llmc2.md` command reference.\n\n## Deliverables\n1. Implement `src/commands/start.rs`:\n   - `run_start(worker: Option\u003cString\u003e, prompt: Option\u003cString\u003e, prompt_file: Option\u003cPathBuf\u003e)` -\u003e Result\u003c()\u003e\n   - Worker selection logic:\n     - If --worker specified: use that worker\n     - Otherwise: select first idle worker not excluded from pool\n     - Error if no idle workers available\n   - Verify worker is idle\n   - Pull latest master into worktree\n   - Copy Tabula.xlsm to worktree\n   - Build full prompt with preamble\n   - Send /clear to worker session\n   - Send prompt to worker session\n   - Update state to working\n   - Update current_prompt field\n   - Update last_activity_unix\n\n2. Prompt building:\n   - Load prompt from --prompt or --prompt-file\n   - Prepend preamble:\n     - \"You are working in: \u003cworktree_path\u003e\"\n     - \"Repository root: \u003crepo_path\u003e\"\n     - \"Follow the conventions in AGENTS.md\"\n     - \"Run validation commands before committing\"\n     - \"Create a single commit with your changes\"\n     - \"Do NOT push to remote\"\n   - Append role_prompt from worker config if present\n\n3. Implement `src/commands/message.rs`:\n   - `run_message(worker: \u0026str, message: \u0026str)` -\u003e Result\u003c()\u003e\n   - Verify worker exists\n   - Verify worker is in valid state for messaging (needs_input, working, rejected)\n   - Send message to worker session (no /clear)\n   - Update last_activity_unix\n   - If was needs_input, transition to working\n\n4. Update CLI in `src/cli.rs`:\n   - start command args: --worker \u003cname\u003e, --prompt \u003ctext\u003e, --prompt-file \u003cpath\u003e\n   - message command args: \u003cworker\u003e, \u003cmessage\u003e\n\n5. Prompt validation:\n   - Prompt must be non-empty\n   - Either --prompt or --prompt-file, not both\n   - --prompt-file must exist and be readable\n\n6. Error handling:\n   - No idle workers -\u003e list current worker states\n   - Worker not found -\u003e list available workers\n   - Worker not idle -\u003e show current state\n   - File read error -\u003e clear message\n\n## Dependencies\n- Requires: dr-5zp (up/down for running workers)\n- Requires: dr-wcq (tmux sender)\n- Requires: dr-pyx (git for pull)\n\n## Testing Instructions\n- Run `cargo test commands::start`\n- Run `cargo test commands::message`\n- Test start with various prompt sources\n- Test message to different worker states\n\n## Acceptance Criteria\n- [ ] start selects idle worker correctly\n- [ ] Full prompt includes preamble\n- [ ] Worker transitions to working state\n- [ ] message sends without clearing context\n- [ ] Error messages list available workers\n\n## Code Style\nFollow the project code style guide in `rules_engine/CLAUDE.md`.\n\n## Manual Testing Instructions\nAfter completing this task, output a \"Manual Testing Instructions\" section describing how to manually verify the work.\n\n## Additional Tasks\nIf you discover issues or additional work needed, file new bd tasks under epic dr-67z.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T06:56:53.132377-08:00","created_by":"dthurn","updated_at":"2026-01-10T06:56:53.132377-08:00","dependencies":[{"issue_id":"dr-yu9","depends_on_id":"dr-5zp","type":"blocks","created_at":"2026-01-10T06:58:39.821061-08:00","created_by":"dthurn"}]}
{"id":"dr-zr2","title":"Tabula V2: Complete Card Data Loading Rewrite","description":"## Overview\n\nComplete rewrite of the card data loading system to replace `tabula_data` with `tabula_data_v2`. This refactor eliminates the legacy `tabula.json` file in favor of loading data directly from TOML and FTL files at runtime, parsing card abilities using `parser_v2` during game initialization, and generating code from the new CLI system.\n\n## Primary Goals\n\n1. Remove `old_tabula_cli` and all v1 tabula crates\n2. Remove all use of `rules_engine/tabula.json`\n3. Remove `is_test_card` distinction from tabula data structures\n4. Rework tabula_data to use TOML and FTL tabula system\n5. Rework tabula_ids \u0026 code generation to use new tabula system\n\n## Architecture\n\n```\nTOML/FTL FILES (cards.toml, test-cards.toml, dreamwell.toml, strings.ftl)\n                    ↓\nTABULA_DATA_V2 CRATE\n  - CardDefinitionRaw (unified, all optional fields)\n  - FluentStrings loader\n  - CardEffectRow, CardListRow\n  - PARSER_V2 Integration (runtime ability parsing)\n                    ↓\nFinal Card Definitions (CardDefinition, DreamwellCardDefinition)\n                    ↓\nTABULA_GENERATED (renamed from tabula_ids)\n  - Generated enums: CardEffectRowType, CardEffectRowTrigger, etc.\n  - Generated constants: TestCard IDs, StringId enum\n```\n\n## Key Design Decisions\n\n1. **Unified CardDefinitionRaw**: Single struct with all optional fields (no separate types per card category)\n2. **Runtime Ability Parsing**: Card abilities parsed at game start using cached `parser_v2` instance\n3. **Fluent Strings**: Two FTL sources - `strings.ftl` (UI) and `card_rules.ftl` (card text)\n4. **No DisplayedAbility**: UI renders text on-demand using `parser_v2` serializers\n5. **TabulaSource Config**: Production loads `cards.toml`, tests load `test-cards.toml`\n6. **Single-Pass Migration**: All dependent crates updated simultaneously, no feature flags\n\n## Key Files\n\n- Design doc: `rules_engine/docs/tabula/tabula_v2_design_document.md`\n- TOML source files: `rules_engine/tabula/` (symlink to client/Assets/StreamingAssets/Tabula/)\n- Existing V1 crate: `rules_engine/src/tabula_data/`\n- Target V2 crate: `rules_engine/src/tabula_data_v2/` (to be created)\n- Code gen target: `rules_engine/src/tabula_generated/` (renamed from tabula_ids)\n\n## Out of Scope\n\n- Changes to parser_v2 internals\n- New card types beyond what exists today\n- Performance optimization of ability parsing\n- UI changes beyond supporting the new serializer API\n","status":"tombstone","priority":1,"issue_type":"epic","created_at":"2026-01-09T18:15:38.146386-08:00","created_by":"dthurn","updated_at":"2026-01-09T18:17:53.350563-08:00","deleted_at":"2026-01-09T18:17:53.350563-08:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"epic"}
